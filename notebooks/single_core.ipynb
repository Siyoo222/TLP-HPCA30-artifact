{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from champsim_parser.result_set.manipulators import get_sim_points\n",
    "from champsim_parser.result_set.manipulators import apply_simpoint, normalize_llc_distill_cache\n",
    "from champsim_parser.result_set.manipulators import pairing_multicore_result_sets, \\\n",
    "    compute_multicore_weighted_ipc, compute_multicore_speedup\n",
    "from champsim_parser.result_parsers import distill_cache_parser, multicore_cache_parser\n",
    "from champsim_parser.parser import MultiCoreParser\n",
    "from champsim_parser.config_parser import new_caches_parser\n",
    "from champsim_parser.experiments.experiments import Experiments\n",
    "from champsim_parser.parser import Parser\n",
    "from IPython.display import display\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def apply_manipulator_to_all(exp, manip, *args):\n",
    "    output = Experiments()\n",
    "\n",
    "    for e in exp.sets:\n",
    "        output += e(manip, *args)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def exclude_specs(name, entry):\n",
    "    re_spec = re.compile(r'^(4.*|6.*)')\n",
    "\n",
    "    return not re_spec.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def only_specs06(name, entry):\n",
    "    re_spec = re.compile(r'^(4.*)')\n",
    "    return re_spec.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def only_specs17(name, entry):\n",
    "    re_spec = re.compile(r'^(6.*)')\n",
    "    return re_spec.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def only_ligra(name, entry):\n",
    "    re_spec = re.compile(r'^ligra_.*')\n",
    "    return re_spec.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def exclude_gapbs(name, entry):\n",
    "    re_gapbs = re.compile(r'^(bc.*|bfs.*|cc.*|pr.*|tc.*|sssp.*)')\n",
    "\n",
    "    return not re_gapbs.match(name)\n",
    "\n",
    "\n",
    "def exclude_ligra(name, entry):\n",
    "    re_ligra = re.compile(r'^ligra_.*')\n",
    "\n",
    "    return not re_ligra.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def only_gapbs(name, entry):\n",
    "    re_gapbs = re.compile(r'^(bc.*|bfs.*|cc.*|pr.*|tc.*|sssp.*)')\n",
    "\n",
    "    return re_gapbs.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def only_spec(name, entry):\n",
    "    re_spec = re.compile(r'^(4.*|6.*)')\n",
    "\n",
    "    return re_spec.match(name) and mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def all_workloads(name, entry):\n",
    "    return mpki_filter(name, entry)\n",
    "\n",
    "\n",
    "def mpki_filter(name, entry):\n",
    "    \"\"\"\n",
    "    This function is deisgned to filter out workload that are either not significant or\n",
    "    that show an unreliable behaviour such as the tc.* workloads.\n",
    "\n",
    "    :param name: The name of the workload.\n",
    "    :param entry: A structured object (typically a dictionnary) whose entries are data computed\n",
    "    based on a post-processing of the ChampSim output files.\n",
    "    :return: A boolean telling if this workload should be used or not.\n",
    "    \"\"\"\n",
    "    # return 'tc' not in name and entry['llc_ref_line_miss_pki'] > 0.0\n",
    "    return entry['llc_ref_line_miss_pki'] > 1.0\n",
    "\n",
    "\n",
    "def set_size(width, fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"\n",
    "\n",
    "    :param width:\n",
    "    :param fraction:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches.\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ration to set aesthetic figure height.\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5 ** (1 / 2) - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    # if width == fig_text_width:\n",
    "    #     fig_height_in /= 2\n",
    "\n",
    "    if width == fig_width:\n",
    "        fig_height_in *= (2.5/5)\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim\n",
    "\n",
    "\n",
    "# Creating the result parser.\n",
    "p = Parser()\n",
    "\n",
    "# Getting SimPoints data (weights and more).\n",
    "simpoints_data = get_sim_points('SimPoints/')\n",
    "\n",
    "# Some configs on matplotlib.\n",
    "tex_fonts = {\n",
    "    # Use Latex to write all text.\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'serif',\n",
    "    # Use 10pt font in plots, to match 10pt font in document.\n",
    "    'axes.labelsize': 8,\n",
    "    'font.size': 10,\n",
    "    # Make the legend/label fonts a little smaller.\n",
    "    'legend.fontsize': 5,\n",
    "    'legend.handlelength': 1.0,\n",
    "    'legend.labelspacing': 0.5,\n",
    "    'legend.columnspacing': 1.0,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "\n",
    "    'hatch.linewidth': 0.15,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(tex_fonts)\n",
    "\n",
    "plot_cmp = 'Greys'\n",
    "\n",
    "# Creating a regular expression to match the trailing \".sdc\" at the end of the single-core workloads.\n",
    "# As it doesn't provide any information we substitute it with an empty string.\n",
    "sub_re_trailing_sdc = re.compile(r'(.sdc)')\n",
    "sub_re_trailing_und = re.compile(r'(_)')\n",
    "\n",
    "\n",
    "# Figure width base on the column width of the Latex document.\n",
    "fig_width = 252\n",
    "fig_text_width = 516\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Core Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing results file containing data relative to simulations comparing designs using no prefetchers what so ever to designs using a prefetcher only in the L1D.\n",
    "raw_data = p.parse(\n",
    "    'results/micro23_04_07_23/', new_caches_parser, distill_cache_parser)\n",
    "raw_data_cpy = deepcopy(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different configurations used to build this plot.\n",
    "cl_baseline_config, config_list = \\\n",
    "    {'bin': 'baseline_cascade_lake_ipcp'}, [\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_double_l1d'}, # 0\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_spp_ppf'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_l1d_filtered_prefetcher'},\n",
    "\n",
    "        # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "        # WIP: This is now design related to the HPCA'30 submission.\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis'}, # 4\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_delayed_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_delayed_tlp'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d'},\n",
    "\n",
    "        # Using a design combining SPP-PPF and Hermes-O as a comparison point for prefetcher accuracy.\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_spp_ppf_hermes_o'}, # 9\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_iso_prefetcher'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_hermes_o_double'},\n",
    "        {'bin': 'baseline_cascade_lake_no_prefetchers'},\n",
    "\n",
    "        {'bin': 'baseline_cascade_lake_spp_ppf'}, # 13\n",
    "        {'bin': 'baseline_cascade_lake_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_spp_ppf_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_tlp_layered_core_l1d_f20_-25'},\n",
    "        {'bin': 'baseline_cascade_lake_no_ipcp'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_block_prefs'},\n",
    "        {'bin': 'baseline_cascade_lake_ipcp_slp'},\n",
    "    ]\n",
    "\n",
    "# Isolating results set based on the given configurations.\n",
    "r_cl_base, r_list = \\\n",
    "    raw_data / cl_baseline_config, [\n",
    "        raw_data / e for e in config_list]\n",
    "\n",
    "temp_res_set = [r_cl_base]\n",
    "\n",
    "temp_res_set.extend(r_list)\n",
    "temp_res_set.append(raw_data_cpy / cl_baseline_config)\n",
    "\n",
    "# Normalizing...\n",
    "for e in temp_res_set:\n",
    "    print(e.sets[0].config)\n",
    "    normalize_llc_distill_cache(e.sets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    'baseline_cascade_lake_no_l1d_prefetcher': 'No Prefetcher',\n",
    "    'baseline_cascade_lake_l1d_filtered_prefetcher': 'TSP',\n",
    "    'baseline_cascade_lake_double_l1d': 'L1D 64KB',\n",
    "    'baseline_cascade_lake_hermes_o': 'Hermes',\n",
    "    'baseline_cascade_lake_hermes_o_no_l1d_prefetcher': 'Hermes no L1D Prefetcher',\n",
    "    'baseline_cascade_lake_spp_ppf': 'PPF',\n",
    "    'baseline_cascade_lake_topt': 'T-OPT',\n",
    "    'baseline_cascade_lake': 'Baseline',\n",
    "\n",
    "    # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "    'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': 'Bimodal Hermes',\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': 'TLP',\n",
    "\n",
    "    'baseline_cascade_lake_ipcp_delayed_hermes_o': 'Delayed Hermes',\n",
    "    'baseline_cascade_lake_ipcp_delayed_tlp': 'Delayed TSP',\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': 'Bimodal TSP',\n",
    "\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': 'Hermes + PPF',\n",
    "    'baseline_cascade_lake_ipcp_iso_prefetcher': '2xIPCP',\n",
    "    'baseline_cascade_lake_ipcp_hermes_o_double': '2xHermes',\n",
    "    'baseline_cascade_lake_no_prefetchers': 'No Prefetchers',\n",
    "\n",
    "    'baseline_cascade_lake_ipcp': 'Baseline',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res_set_gapbs = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_gapbs)\n",
    "                       for e in temp_res_set[1:]]\n",
    "final_res_set_spec = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_spec)\n",
    "                      for e in temp_res_set[1:]]\n",
    "final_res_set_spec06 = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_specs06)\n",
    "                        for e in temp_res_set[1:]]\n",
    "final_res_set_spec17 = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_specs17)\n",
    "                        for e in temp_res_set[1:]]\n",
    "final_res_set_ligra = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_ligra)\n",
    "                       for e in temp_res_set[1:]]\n",
    "final_res_set_all = [apply_manipulator_to_all(\n",
    "    e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, exclude_ligra) for e in temp_res_set[1:]]\n",
    "\n",
    "speedup_gapbs_keys = [e for e in final_res_set_gapbs[0].sets[0].keys()\n",
    "                      if e != 'mean']\n",
    "gapbs_keys = [e for e in final_res_set_gapbs[0].sets[0].keys()\n",
    "              if e != 'geomean']\n",
    "speedup_spec_keys = [e for e in final_res_set_spec[0].sets[0].keys()\n",
    "                     if e != 'mean']\n",
    "spec_keys = [e for e in final_res_set_spec[0].sets[0].keys()\n",
    "             if e != 'geomean']\n",
    "speedup_spec06_keys = [e for e in final_res_set_spec06[0].sets[0].keys()\n",
    "                       if e != 'mean']\n",
    "spec06_keys = [e for e in final_res_set_spec06[0].sets[0].keys()\n",
    "               if e != 'geomean']\n",
    "speedup_spec17_keys = [e for e in final_res_set_spec17[0].sets[0].keys()\n",
    "                       if e != 'mean']\n",
    "spec17_keys = [e for e in final_res_set_spec17[0].sets[0].keys()\n",
    "               if e != 'geomean']\n",
    "speedup_ligra_keys = [e for e in final_res_set_ligra[0].sets[0].keys()\n",
    "                      if e != 'mean']\n",
    "ligra_keys = [e for e in final_res_set_ligra[0].sets[0].keys()\n",
    "              if e != 'geomean']\n",
    "speedup_all_keys = [\n",
    "    e for e in final_res_set_all[0].sets[0].keys() if e != 'mean']\n",
    "all_keys = [\n",
    "    e for e in final_res_set_all[0].sets[0].keys() if e != 'geomean']\n",
    "\n",
    "\n",
    "workload_sets = [final_res_set_spec, final_res_set_gapbs, final_res_set_all]\n",
    "\n",
    "print(len(gapbs_keys), len(spec_keys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpkis_spec = {\n",
    "    'baseline_llc_mpki': [final_res_set_spec[-1].sets[0][e]['llc_mpki'] for e in spec_keys if e != 'mean'],\n",
    "}\n",
    "\n",
    "df_llc_mpki_spec = pandas.DataFrame(\n",
    "    dict_llc_mpkis_spec, columns=dict_llc_mpkis_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "df_llc_mpki_spec.sort_values(by='baseline_llc_mpki', inplace=True)\n",
    "\n",
    "# display(df_llc_mpki_spec)\n",
    "\n",
    "dict_llc_mpki_gapbs = {\n",
    "    'baseline_llc_mpki': [final_res_set_gapbs[-1].sets[0][e]['llc_mpki'] for e in gapbs_keys if e != 'mean'],\n",
    "}\n",
    "df_llc_mpki_gapbs = pandas.DataFrame(\n",
    "    dict_llc_mpki_gapbs, columns=dict_llc_mpki_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "df_llc_mpki_gapbs.sort_values(by='baseline_llc_mpki', inplace=True)\n",
    "\n",
    "# display(df_llc_mpki_gapbs)\n",
    "\n",
    "# Updating the keys with proper ordering.\n",
    "speedup_spec_keys, speedup_gapbs_keys = df_llc_mpki_spec.index.to_list(\n",
    "), df_llc_mpki_gapbs.index.to_list()\n",
    "spec_keys, gapbs_keys = df_llc_mpki_spec.index.to_list(\n",
    "), df_llc_mpki_gapbs.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sets, res_keys = [final_res_set_spec, final_res_set_gapbs], [\n",
    "    [k for k in speedup_spec_keys if k != 'geomean'], [k for k in speedup_gapbs_keys if k != 'geomean']]\n",
    "speedup_list, speedup_pref_list, speedup_all_keys = [], [], []\n",
    "\n",
    "dict_speedup = {\n",
    "    # 'baseline_cascade_lake_double_l1d': [],\n",
    "    'baseline_cascade_lake_spp_ppf': [],\n",
    "    'baseline_cascade_lake_hermes_o': [],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [],\n",
    "    'baseline_cascade_lake_ipcp_delayed_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [],\n",
    "\n",
    "    # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [],\n",
    "    # 'baseline_cascade_lake_ipcp_iso_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': [],\n",
    "    'baseline_cascade_lake_no_prefetchers': [],\n",
    "    'baseline_cascade_lake_ipcp_block_prefs': [],\n",
    "    'baseline_cascade_lake_ipcp_slp': [],\n",
    "}\n",
    "\n",
    "for set, keys in zip(res_sets, res_keys):\n",
    "    # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_double_l1d'].extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_spp_ppf'].extend(\n",
    "        [set[1].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_hermes_o'].extend(\n",
    "        [set[2].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_ipcp_spp_ppf_hermes_o'].extend(\n",
    "        [set[9].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_ipcp_delayed_hermes_o'].extend([set[6].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[3].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_ipcp_delayed_tlp'].extend([set[7].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "    # dict_speedup['baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_ipcp_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "        [set[5].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_ipcp_iso_prefetcher'].extend(\n",
    "    #     [set[10].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_ipcp_hermes_o_double'].extend(\n",
    "    #     [set[11].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "        [set[12].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_ipcp_block_prefs'].extend(\n",
    "        [set[18].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_ipcp_slp'].extend(\n",
    "        [set[19].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "    # Adding keys to the list.\n",
    "    speedup_all_keys.extend(keys)\n",
    "\n",
    "# for k, v in dict_speedup.items():\n",
    "#     dict_speedup[k] = sorted(v)\n",
    "\n",
    "df_speedup_hermes_o = pandas.DataFrame(\n",
    "    dict_speedup, columns=dict_speedup.keys(), index=speedup_all_keys)\n",
    "\n",
    "# df_tmp = df_speedup_hermes_o[df_speedup_hermes_o.index != 'mean'].sort_values(\n",
    "#     by=df_speedup_hermes_o.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_speedup_hermes_o = df_tmp\n",
    "\n",
    "df_speedup_hermes_o -= 1.0\n",
    "df_speedup_hermes_o *= 100.0\n",
    "\n",
    "# Creating a DataFrame containing the geo-means for the different benchmark suites.\n",
    "speedup_gmean_list, speedup_pref_gmean_list, gmean_keys = [s[0].sets[0]['geomean']['speedup']\n",
    "                                                           for s in [*res_sets, final_res_set_all]], \\\n",
    "    [s[0].sets[0]['geomean']['speedup']\n",
    "     for s in [*res_sets, final_res_set_all]], \\\n",
    "    ['ALL']\n",
    "\n",
    "df_speedup_gmean = pandas.DataFrame({\n",
    "    # 'baseline_cascade_lake_ipcp': speedup_pref_gmean_list,\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o': speedup_gmean_list,\n",
    "    # 'baseline_cascade_lake_double_l1d': [s[0].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_spp_ppf': gmean(df_speedup_hermes_o['baseline_cascade_lake_spp_ppf'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_hermes_o'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_spp_ppf_hermes_o'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_ipcp_delayed_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_delayed_hermes_o'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [s[7].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [s[4].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_ipcp_iso_prefetcher': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_iso_prefetcher'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_hermes_o_double'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_no_prefetchers': gmean(df_speedup_hermes_o['baseline_cascade_lake_no_prefetchers'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_ipcp_block_prefs': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_block_prefs'] / 100.0 + 1.0),\n",
    "    'baseline_cascade_lake_ipcp_slp': gmean(df_speedup_hermes_o['baseline_cascade_lake_ipcp_slp'] / 100.0 + 1.0),\n",
    "}, index=gmean_keys)\n",
    "\n",
    "df_speedup_gmean -= 1.0\n",
    "df_speedup_gmean *= 100.0\n",
    "\n",
    "labels_dict.update({\n",
    "    # 'baseline_cascade_lake_ipcp': 'IPCP',\n",
    "    'baseline_cascade_lake_ipcp_hermes_o': 'Hermes-O',\n",
    "    'baseline_cascade_lake_ipcp_block_prefs': 'Block Prefs',\n",
    "    'baseline_cascade_lake_ipcp_slp': 'SLP',\n",
    "})\n",
    "\n",
    "display(df_speedup_hermes_o)\n",
    "display(df_speedup_gmean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hermes_o_speedup = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hermes_o_speedup.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 5, figure=fig_hermes_o_speedup)\n",
    "\n",
    "ax_hermes_o_speedup, ax_hermes_o_gmean = fig_hermes_o_speedup.add_subplot(\n",
    "    gs[0, :4]), fig_hermes_o_speedup.add_subplot(gs[0, 4:])\n",
    "ax_hermes_o_speedup.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_speedup_hermes_o.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_speedup_hermes_o.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.05\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "# for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "#     ax_hermes_o_speedup.bar(index + i * (bar_width) + (cat_spacing / 2),\n",
    "#                     df_speedup_hermes_o[e], width=bar_width, edgecolor='black', linewidth=0.2, align='edge', label=labels_dict[e], color=c)\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    ax_hermes_o_speedup.scatter(index + i * (bar_width) + (cat_spacing / 2),\n",
    "                                df_speedup_hermes_o[e],\n",
    "                                s=5,\n",
    "                                marker=m,\n",
    "                                # width=bar_width,\n",
    "                                edgecolor='black',\n",
    "                                linewidths=0.5,\n",
    "                                # align='edge',\n",
    "                                label=labels_dict[e], color=c)\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_hermes_o_speedup.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, -10), ha='center', va='center', size=7)\n",
    "ax_hermes_o_speedup.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, -10), ha='center', va='center', size=7)\n",
    "\n",
    "ax_hermes_o_speedup.axvspan(xmin=0, xmax=len(\n",
    "    spec_keys) + 1, color='grey', alpha=0.25, zorder=-1)\n",
    "\n",
    "ax_hermes_o_speedup.set_xticks(index)\n",
    "# ax_hermes_o_speedup.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_hermes_o_speedup.set_xticklabels([])\n",
    "ax_hermes_o_speedup.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_hermes_o_speedup.grid(True, which='minor', color='grey',\n",
    "                         linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_hermes_o_speedup.set_axisbelow(True)\n",
    "\n",
    "ax_hermes_o_speedup.set_ylabel(r'Speedup (\\%)', fontsize=8)\n",
    "\n",
    "ax_hermes_o_speedup.tick_params(axis='both')\n",
    "ax_hermes_o_speedup.tick_params(labeltop=False)\n",
    "ax_hermes_o_speedup.tick_params(axis='x',\n",
    "                                which='both',\n",
    "                                bottom=False,\n",
    "                                top=False)\n",
    "\n",
    "ax_hermes_o_speedup.set_ylim([-15.0, 30.0])\n",
    "\n",
    "ax_hermes_o_speedup.yaxis.set_major_locator(MultipleLocator(30))\n",
    "ax_hermes_o_speedup.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_hermes_o_speedup.yaxis.set_minor_locator(MultipleLocator(15))\n",
    "ax_hermes_o_speedup.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "for tick in ax_hermes_o_speedup.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_hermes_o_speedup.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0, ncol=2,\n",
    "                           fontsize=5\n",
    "                           )\n",
    "\n",
    "# Working on the second subplot that will contain the mean for each benchmark suite.\n",
    "xticklabels = gmean_keys\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    bars = ax_hermes_o_gmean.bar(index + i * bar_width + cat_spacing / 2,\n",
    "                                 df_speedup_gmean[e], width=bar_width, linewidth=0.2, edgecolor='black', align='edge', label=labels_dict[e], color=c)\n",
    "\n",
    "for b, k in zip(ax_hermes_o_gmean.patches, key_list):\n",
    "    print(k)\n",
    "    ax_hermes_o_gmean.annotate(labels_dict[k], (b.get_x() + b.get_width() / 2, 8), size=4, rotation=90,\n",
    "                            #    ha='center',\n",
    "                               # va='center',\n",
    "                               # xytext=(0, 10), textcoords='offset points'\n",
    "                               )\n",
    "\n",
    "ax_hermes_o_gmean.set_xticks(index)\n",
    "ax_hermes_o_gmean.set_xticklabels([])\n",
    "# ax_hermes_o_gmean.bar_label(ax_hermes_o_gmean.containers[-1], labels=gmean_keys, label_type='edge', rotation=90, fontsize=5, padding=3)\n",
    "ax_hermes_o_gmean.set_ylim([-1.0, 20.0])\n",
    "ax_hermes_o_gmean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_hermes_o_gmean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_speedup_alt.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_speedup_alt.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sets, res_keys = [final_res_set_spec,\n",
    "                      final_res_set_gapbs], [spec_keys, gapbs_keys]\n",
    "dram_trans_pref_list, dram_trans_list, dram_trans_all_keys = [], [], []\n",
    "\n",
    "# for set, keys in zip(res_sets, res_keys):\n",
    "#     # dram_trans_pref_list.extend([set[0].sets[0][k]['dram']['transactions'] /\n",
    "#     #                        set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "#     dram_trans_list.extend([set[0].sets[0][k]['dram']['transactions'] /\n",
    "#                            set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "#     # Adding keys to the list.\n",
    "#     dram_trans_all_keys.extend(keys)\n",
    "\n",
    "# dict_dram_trans = {\n",
    "#     # 'baseline_cascade_lake_ipcp': dram_trans_pref_list,\n",
    "#     'baseline_cascade_lake_ipcp_hermes_o': dram_trans_list,\n",
    "# }\n",
    "\n",
    "dict_dram_trans = {\n",
    "    # 'baseline_cascade_lake_double_l1d': [],\n",
    "    'baseline_cascade_lake_spp_ppf': [],\n",
    "    'baseline_cascade_lake_hermes_o': [],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [],\n",
    "\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [],\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': [],\n",
    "    # 'baseline_cascade_lake_no_prefetchers': [],\n",
    "}\n",
    "\n",
    "for set, keys in zip(res_sets, res_keys):\n",
    "    # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_double_l1d'].extend([set[0].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_spp_ppf'].extend(\n",
    "        [set[1].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_hermes_o'].extend(\n",
    "        [set[2].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_ipcp_spp_ppf_hermes_o'].extend(\n",
    "        [set[9].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_ipcp_delayed_hermes_o'].extend([set[6].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[3].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_ipcp_delayed_tlp'].extend([set[7].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "    # dict_dram_trans['baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_ipcp_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "        [set[5].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_ipcp_hermes_o_double'].extend(\n",
    "    #     [set[11].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "    #     [set[12].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "    # Adding keys to the list.\n",
    "    dram_trans_all_keys.extend(keys)\n",
    "\n",
    "# for k, v in dict_dram_trans.items():\n",
    "#     dict_dram_trans[k] = sorted(v)\n",
    "\n",
    "df_dram_trans = pandas.DataFrame(\n",
    "    dict_dram_trans, columns=dict_dram_trans.keys(), index=dram_trans_all_keys)\n",
    "\n",
    "df_dram_trans -= 1.0\n",
    "df_dram_trans *= 100.0\n",
    "\n",
    "# df_tmp = df_dram_trans[df_dram_trans.index != 'mean'].sort_values(\n",
    "#     by=df_dram_trans.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_dram_trans = df_tmp\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_dram_trans.sort_values(\n",
    "#     by='mean', axis='columns', inplace=True, ascending=True)\n",
    "# df_tmp = df_dram_trans[df_dram_trans.index != 'mean'].sort_values(\n",
    "#     by=df_dram_trans.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_dram_trans = pandas.concat(\n",
    "#     [df_tmp, df_dram_trans[df_dram_trans.index == 'mean']])\n",
    "\n",
    "# Creating a DataFrame containing the means for the different benchmark suites.\n",
    "dram_trans_pref_mean_list, dram_trans_mean_list, mean_keys = [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]], \\\n",
    "    [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions']\n",
    "     for s in [*res_sets, final_res_set_all]], ['ALL']\n",
    "\n",
    "df_dram_trans_mean = pandas.DataFrame({\n",
    "    # 'baseline_cascade_lake_ipcp': dram_trans_pref_mean_list,\n",
    "    # 'baseline_cascade_lake_double_l1d': [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_spp_ppf': np.nanmean(df_dram_trans['baseline_cascade_lake_spp_ppf']),\n",
    "    'baseline_cascade_lake_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_hermes_o']),\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_ipcp_spp_ppf_hermes_o']),\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_ipcp_delayed_hermes_o']),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [s[7].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [s[4].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': np.nanmean(df_dram_trans['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25']),\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': np.nanmean(df_dram_trans['baseline_cascade_lake_ipcp_hermes_o_double']),\n",
    "    # 'baseline_cascade_lake_no_prefetchers': np.nanmean(df_dram_trans['baseline_cascade_lake_no_prefetchers']),\n",
    "}, index=mean_keys)\n",
    "\n",
    "# df_dram_trans_mean -= 1.0\n",
    "# df_dram_trans_mean *= 100.0\n",
    "# del(df_tmp)\n",
    "\n",
    "# Concatenating the 50 highest values with the means per benchmark suites.\n",
    "# df_dram_trans = pandas.concat([df_tmp, df_dram_trans_mean])\n",
    "\n",
    "display(df_dram_trans)\n",
    "display(df_dram_trans_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hermes_o_dram_trans = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hermes_o_dram_trans.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 5, figure=fig_hermes_o_dram_trans)\n",
    "\n",
    "ax_hermes_o_dram_trans, ax_hermes_o_dram_trans_mean = fig_hermes_o_dram_trans.add_subplot(\n",
    "    gs[0, :4]), fig_hermes_o_dram_trans.add_subplot(gs[0, 4:])\n",
    "ax_hermes_o_dram_trans.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_dram_trans.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_dram_trans.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.05\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "# for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "#     ax_hermes_o_dram_trans.bar(index + i * (bar_width) + (cat_spacing / 2),\n",
    "#                     df_speedup_hermes_o[e], width=bar_width, edgecolor='black', linewidth=0.2, align='edge', label=labels_dict[e], color=c)\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    ax_hermes_o_dram_trans.scatter(index + i * (bar_width) + (cat_spacing / 2),\n",
    "                                   df_dram_trans[e],\n",
    "                                   s=5,\n",
    "                                   marker=m,\n",
    "                                   edgecolor='black',\n",
    "                                   linewidths=0.5,\n",
    "                                   # width=bar_width, edgecolor='black', linewidth=0.2, align='edge',\n",
    "                                   label=labels_dict[e], color=c)\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_hermes_o_dram_trans.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, -75), ha='center', va='center', size=7)\n",
    "ax_hermes_o_dram_trans.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, -75), ha='center', va='center', size=7)\n",
    "\n",
    "ax_hermes_o_dram_trans.axvspan(xmin=0, xmax=len(\n",
    "    spec_keys) + 1, color='grey', alpha=0.25, zorder=-1)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_xticks(index)\n",
    "# ax_hermes_o_dram_trans.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_hermes_o_dram_trans.set_xticklabels([])\n",
    "ax_hermes_o_dram_trans.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_hermes_o_dram_trans.set_axisbelow(True)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_ylabel(\n",
    "    'Increase DRAM\\nTransactions (\\%)', fontsize=8)\n",
    "\n",
    "ax_hermes_o_dram_trans.tick_params(axis='both')\n",
    "ax_hermes_o_dram_trans.tick_params(labeltop=False)\n",
    "ax_hermes_o_dram_trans.tick_params(axis='x',\n",
    "                                   which='both',\n",
    "                                   bottom=False,\n",
    "                                   top=False)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_ylim([-125.0, 125.0])\n",
    "\n",
    "for tick in ax_hermes_o_dram_trans.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_hermes_o_dram_trans.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0, ncol=2,\n",
    "                              fontsize=5\n",
    "                              )\n",
    "\n",
    "# Working on the second subplot that will contain the mean for each benchmark suite.\n",
    "xticklabels = mean_keys\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    ax_hermes_o_dram_trans_mean.bar(index + i * bar_width + cat_spacing / 2,\n",
    "                                    df_dram_trans_mean[e], width=bar_width, linewidth=0.2, edgecolor='black', align='edge', label=labels_dict[e], color=c)\n",
    "\n",
    "for b, k in zip(ax_hermes_o_dram_trans_mean.patches, key_list):\n",
    "    print(k)\n",
    "    ax_hermes_o_dram_trans_mean.annotate(labels_dict[k], (b.get_x() + b.get_width() / 2, 17.5), size=4, rotation=90,\n",
    "                                         #    ha='center',\n",
    "                                         # va='center',\n",
    "                                         # xytext=(0, 10), textcoords='offset points'\n",
    "                                         )\n",
    "\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_major_locator(MultipleLocator(100))\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_minor_locator(MultipleLocator(25))\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "ax_hermes_o_dram_trans_mean.set_xticks(index)\n",
    "ax_hermes_o_dram_trans_mean.set_xticklabels([])\n",
    "# ax_hermes_o_dram_trans_mean.bar_label(ax_hermes_o_dram_trans_mean.containers[1], labels=gmean_keys, label_type='edge', rotation=90, fontsize=5, padding=3)\n",
    "ax_hermes_o_dram_trans_mean.set_ylim([-40.0, 100.0])\n",
    "ax_hermes_o_dram_trans_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_hermes_o_dram_trans_mean.grid(True, which='minor', color='grey',\n",
    "                         linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_hermes_o_dram_trans_mean.set_axisbelow(True)\n",
    "ax_hermes_o_dram_trans_mean.tick_params(axis='y', which='minor', labelsize=7.5)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_dram_transactions_alt.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_dram_transactions_alt.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_accuracy = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[9].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_l1d_prefetcher': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_l1d_accuracy = pandas.DataFrame(\n",
    "    dict_l1d_accuracy, columns=dict_l1d_accuracy.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "df_l1d_accuracy *= 100.0\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_accuracy.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_accuracy[df_l1d_accuracy.index != 'geomean'].sort_values(\n",
    "#     by=df_l1d_accuracy.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_accuracy = pandas.concat(\n",
    "#     [df_tmp, df_l1d_accuracy[df_l1d_accuracy.index == 'geomean']])\n",
    "\n",
    "display(df_l1d_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the actual plotting material.\n",
    "fig_l1d_pref_accuracy = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_l1d_pref_accuracy.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 1, figure=fig_l1d_pref_accuracy)\n",
    "\n",
    "fig_l1d_pref_accuracy = fig_l1d_pref_accuracy.add_subplot(\n",
    "    gs[:])\n",
    "fig_l1d_pref_accuracy.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_accuracy.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_accuracy.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based_2k_entries', 'hermes_o_pc_based', 'popet_o', 'hermes_o_perfect']\n",
    "\n",
    "cat_spacing = 0.1\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    fig_l1d_pref_accuracy.bar(index + (i - 1) * (bar_width),\n",
    "                              df_l1d_accuracy[e], width=bar_width, edgecolor='black', linewidth=0.2, align='center', label=labels_dict[e], color=c)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_xticks(index)\n",
    "fig_l1d_pref_accuracy.set_xticklabels(xticklabels, rotation=0)\n",
    "# fig_l1d_pref_accuracy.set_xticklabels([])\n",
    "fig_l1d_pref_accuracy.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "fig_l1d_pref_accuracy.set_axisbelow(True)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_ylabel(r'Accuracy (\\%)')\n",
    "\n",
    "fig_l1d_pref_accuracy.tick_params(axis='both')\n",
    "fig_l1d_pref_accuracy.tick_params(labeltop=False)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_ylim([0, 100.0])\n",
    "\n",
    "fig_l1d_pref_accuracy.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0,\n",
    "                             ncol=3,\n",
    "                             fontsize=5,\n",
    "                             #    labelspacing=1.0,\n",
    "                             #    bbox_to_anchor=(0, 0.925, 1, 0.25),\n",
    "                             #    mode='expand'\n",
    "                             )\n",
    "\n",
    "for tick in fig_l1d_pref_accuracy.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('center')\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_l1d_prefetcher_accuracy.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_l1d_prefetcher_accuracy.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_coverage = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp': [s[-1].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[9].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_l1d_coverage = pandas.DataFrame(\n",
    "    dict_l1d_coverage, columns=dict_l1d_coverage.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "df_l1d_coverage = 1.0 - df_l1d_coverage\n",
    "df_l1d_coverage *= 100.0\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_coverage.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_coverage[df_l1d_coverage.index != 'geomean'].sort_values(\n",
    "#     by=df_l1d_coverage.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_coverage = pandas.concat(\n",
    "#     [df_tmp, df_l1d_coverage[df_l1d_coverage.index == 'geomean']])\n",
    "\n",
    "display(df_l1d_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpki = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp': [s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[9].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_llc_mpki = pandas.DataFrame(\n",
    "    dict_llc_mpki, columns=dict_llc_mpki.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "display(df_llc_mpki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpki = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp': [s[17].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[13].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[14].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[15].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[16].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_llc_mpki = pandas.DataFrame(\n",
    "    dict_llc_mpki, columns=dict_llc_mpki.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "display(df_llc_mpki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sets, res_keys = [final_res_set_gapbs], [[k for k in gapbs_keys if k != 'mean']]\n",
    "speedup_list, speedup_pref_list, speedup_all_keys = [], [], []\n",
    "\n",
    "dict_saved_llc_misses = {\n",
    "    # 'baseline_cascade_lake_double_l1d': [],\n",
    "    'baseline_cascade_lake_spp_ppf': [],\n",
    "    'baseline_cascade_lake_hermes_o': [],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [],\n",
    "\n",
    "    # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [],\n",
    "    'baseline_cascade_lake_ipcp': [],\n",
    "    # 'baseline_cascade_lake_ipcp_iso_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': [],\n",
    "    # 'baseline_cascade_lake_no_prefetchers': [],\n",
    "}\n",
    "\n",
    "for set, keys in zip(res_sets, res_keys):\n",
    "    # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_double_l1d'].extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_saved_llc_misses['baseline_cascade_lake_ipcp'].extend(\n",
    "        [set[-1].sets[0][k]['llc_mpki'] for k in keys])\n",
    "    dict_saved_llc_misses['baseline_cascade_lake_spp_ppf'].extend(\n",
    "        [set[1].sets[0][k]['llc_mpki'] for k in keys])\n",
    "    dict_saved_llc_misses['baseline_cascade_lake_hermes_o'].extend(\n",
    "        [set[2].sets[0][k]['llc_mpki'] for k in keys])\n",
    "    dict_saved_llc_misses['baseline_cascade_lake_ipcp_spp_ppf_hermes_o'].extend(\n",
    "        [set[9].sets[0][k]['llc_mpki'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_delayed_hermes_o'].extend([set[6].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[3].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_delayed_tlp'].extend([set[7].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "        [set[5].sets[0][k]['llc_mpki'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_iso_prefetcher'].extend(\n",
    "    #     [set[10].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_ipcp_hermes_o_double'].extend(\n",
    "    #     [set[11].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_saved_llc_misses['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "    #     [set[12].sets[0][k]['llc_mpki'] for k in keys])\n",
    "\n",
    "# for set, keys in zip(res_sets, res_keys):\n",
    "#     # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_double_l1d'].extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "#     dict_saved_llc_misses['baseline_cascade_lake_ipcp'].extend(\n",
    "#         [set[-1].sets[0][k]['llc_mpki'] / set[17].sets[0][k]['llc_mpki'] for k in keys])\n",
    "#     dict_saved_llc_misses['baseline_cascade_lake_spp_ppf'].extend(\n",
    "#         [set[1].sets[0][k]['llc_mpki'] / set[13].sets[0][k]['llc_mpki'] for k in keys])\n",
    "#     dict_saved_llc_misses['baseline_cascade_lake_hermes_o'].extend(\n",
    "#         [set[2].sets[0][k]['llc_mpki'] / set[14].sets[0][k]['llc_mpki'] for k in keys])\n",
    "#     dict_saved_llc_misses['baseline_cascade_lake_ipcp_spp_ppf_hermes_o'].extend(\n",
    "#         [set[9].sets[0][k]['llc_mpki'] / set[15].sets[0][k]['llc_mpki'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_delayed_hermes_o'].extend([set[6].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[3].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_delayed_tlp'].extend([set[7].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['speedup'] for k in keys])\n",
    "#     dict_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "#         [set[5].sets[0][k]['llc_mpki'] / set[16].sets[0][k]['llc_mpki'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_iso_prefetcher'].extend(\n",
    "#     #     [set[10].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_ipcp_hermes_o_double'].extend(\n",
    "#     #     [set[11].sets[0][k]['speedup'] for k in keys])\n",
    "#     # dict_saved_llc_misses['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "#     #     [set[12].sets[0][k]['llc_mpki'] for k in keys])\n",
    "\n",
    "    # Adding keys to the list.\n",
    "    speedup_all_keys.extend(keys)\n",
    "\n",
    "# for k, v in dict_saved_llc_misses.items():\n",
    "#     dict_saved_llc_misses[k] = sorted(v)\n",
    "\n",
    "df_saved_llc_misses = pandas.DataFrame(\n",
    "    dict_saved_llc_misses, columns=dict_saved_llc_misses.keys(), index=speedup_all_keys)\n",
    "\n",
    "# df_tmp = df_saved_llc_misses[df_saved_llc_misses.index != 'mean'].sort_values(\n",
    "#     by=df_saved_llc_misses.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_saved_llc_misses = df_tmp\n",
    "\n",
    "# df_saved_llc_misses = 1.0 - df_saved_llc_misses\n",
    "# df_saved_llc_misses *= 100.0\n",
    "\n",
    "# Creating a DataFrame containing the geo-means for the different benchmark suites.\n",
    "mean_keys = ['ALL']\n",
    "\n",
    "df_saved_llc_misses_mean = pandas.DataFrame({\n",
    "    # 'baseline_cascade_lake_ipcp': speedup_pref_gmean_list,\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o': speedup_gmean_list,\n",
    "    # 'baseline_cascade_lake_double_l1d': [s[0].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_ipcp': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp']),\n",
    "    'baseline_cascade_lake_spp_ppf': np.mean(df_saved_llc_misses['baseline_cascade_lake_spp_ppf']),\n",
    "    'baseline_cascade_lake_hermes_o': np.mean(df_saved_llc_misses['baseline_cascade_lake_hermes_o']),\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp_spp_ppf_hermes_o']),\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_hermes_o': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp_delayed_hermes_o'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_delayed_tlp': [s[7].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_core_l1d_-15_-35_bis': [s[4].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25']),\n",
    "    # 'baseline_cascade_lake_ipcp_iso_prefetcher': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp_iso_prefetcher'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o_double': np.mean(df_saved_llc_misses['baseline_cascade_lake_ipcp_hermes_o_double'] / 100.0 + 1.0),\n",
    "    # 'baseline_cascade_lake_no_prefetchers': np.mean(df_saved_llc_misses['baseline_cascade_lake_no_prefetchers'] / 100.0 + 1.0),\n",
    "}, index=mean_keys)\n",
    "\n",
    "# df_saved_llc_misses_mean -= 1.0\n",
    "# df_saved_llc_misses_mean *= 100.0\n",
    "\n",
    "labels_dict.update({\n",
    "    # 'baseline_cascade_lake_ipcp': 'IPCP',\n",
    "    'baseline_cascade_lake_ipcp_hermes_o': 'Hermes-O',\n",
    "})\n",
    "\n",
    "display(df_saved_llc_misses)\n",
    "display(df_saved_llc_misses_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the actual plotting material.\n",
    "fig_l1d_pref_coverage = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_l1d_pref_coverage.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 1, figure=fig_l1d_pref_coverage)\n",
    "\n",
    "fig_l1d_pref_coverage = fig_l1d_pref_coverage.add_subplot(\n",
    "    gs[:])\n",
    "fig_l1d_pref_coverage.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_coverage.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_coverage.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based_2k_entries', 'hermes_o_pc_based', 'popet_o', 'hermes_o_perfect']\n",
    "\n",
    "cat_spacing = 0.1\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    fig_l1d_pref_coverage.bar(index + (i - 1) * (bar_width),\n",
    "                              df_l1d_coverage[e], width=bar_width, edgecolor='black', linewidth=0.2, align='center', label=labels_dict[e], color=c)\n",
    "\n",
    "fig_l1d_pref_coverage.set_xticks(index)\n",
    "fig_l1d_pref_coverage.set_xticklabels(xticklabels, rotation=0)\n",
    "# fig_l1d_pref_coverage.set_xticklabels([])\n",
    "fig_l1d_pref_coverage.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "fig_l1d_pref_coverage.set_axisbelow(True)\n",
    "\n",
    "fig_l1d_pref_coverage.set_ylabel('LLC MPKI\\nReduction (\\%)')\n",
    "\n",
    "fig_l1d_pref_coverage.tick_params(axis='both')\n",
    "fig_l1d_pref_coverage.tick_params(labeltop=False)\n",
    "\n",
    "fig_l1d_pref_coverage.set_ylim([-10.0, 10.0])\n",
    "\n",
    "fig_l1d_pref_coverage.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0,\n",
    "                             ncol=4,\n",
    "                             fontsize=5,\n",
    "                             #    labelspacing=1.0,\n",
    "                             #    bbox_to_anchor=(0, 0.925, 1, 0.25),\n",
    "                             #    mode='expand'\n",
    "                             )\n",
    "\n",
    "for tick in fig_l1d_pref_coverage.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('center')\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_l1d_prefetcher_coverage.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_evaluation_l1d_prefetcher_coverage.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_offchip_mispred_hermes_spec = {\n",
    "    'offchip_pred_l1d': [final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l1d'] for k in spec_keys if k != 'mean'],\n",
    "    'offchip_pred_l2c': [final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l2c'] for k in spec_keys if k != 'mean'],\n",
    "    'offchip_pred_l2c_llc': [final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l2c_llc'] for k in spec_keys if k != 'mean'],\n",
    "    'offchip_pred_dram': [1 - (final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l2c_llc'] + final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l1d'] + final_res_set_spec[2].sets[0][k]['offchip_pred']['miss_hit_l2c']) for k in spec_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_split_offchip_mispred_hermes_spec = pandas.DataFrame(\n",
    "    dict_split_offchip_mispred_hermes_spec, columns=dict_split_offchip_mispred_hermes_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_split_offchip_mispred_hermes_spec.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_split_offchip_mispred_hermes_spec[df_split_offchip_mispred_hermes_spec.index != 'mean'].sort_values(\n",
    "#     by=df_split_offchip_mispred_hermes_spec.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_split_offchip_mispred_hermes_spec = pandas.concat(\n",
    "#     [df_tmp, df_split_offchip_mispred_hermes_spec[df_split_offchip_mispred_hermes_spec.index == 'mean']])\n",
    "\n",
    "df_split_offchip_mispred_hermes_spec *= 100.0\n",
    "\n",
    "# speedup_gapbs_keys = df_split_offchip_mispred_hermes_spec.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "display(df_split_offchip_mispred_hermes_spec)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'offchip_pred_l1d': 'L1D',\n",
    "    'offchip_pred_l2c_llc': 'L2C/LLC',\n",
    "    'offchip_pred_dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_split_offchip_mispred_hermes_gapbs = {\n",
    "    'offchip_pred_l1d': [final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l1d'] for k in gapbs_keys if k != 'mean'],\n",
    "    'offchip_pred_l2c': [final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l2c'] for k in gapbs_keys if k != 'mean'],\n",
    "    'offchip_pred_l2c_llc': [final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l2c_llc'] for k in gapbs_keys if k != 'mean'],\n",
    "    'offchip_pred_dram': [1 - (final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l2c_llc'] + final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l1d'] + final_res_set_gapbs[2].sets[0][k]['offchip_pred']['miss_hit_l2c']) for k in gapbs_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_split_offchip_mispred_hermes_gapbs = pandas.DataFrame(\n",
    "    dict_split_offchip_mispred_hermes_gapbs, columns=dict_split_offchip_mispred_hermes_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_split_offchip_mispred_hermes_gapbs.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_split_offchip_mispred_hermes_gapbs[df_split_offchip_mispred_hermes_gapbs.index != 'mean'].sort_values(\n",
    "#     by=df_split_offchip_mispred_hermes_gapbs.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_split_offchip_mispred_hermes_gapbs = pandas.concat(\n",
    "#     [df_tmp, df_split_offchip_mispred_hermes_gapbs[df_split_offchip_mispred_hermes_gapbs.index == 'mean']])\n",
    "\n",
    "df_split_offchip_mispred_hermes_gapbs *= 100.0\n",
    "\n",
    "# speedup_gapbs_keys = df_split_offchip_mispred_hermes_gapbs.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "display(df_split_offchip_mispred_hermes_gapbs)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'offchip_pred_l1d': 'L1D',\n",
    "    'offchip_pred_l2c': 'L2C',\n",
    "    'offchip_pred_l2c_llc': 'LLC',\n",
    "    'offchip_pred_dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_offchip_mispred_hermes = pandas.concat(\n",
    "    [df_split_offchip_mispred_hermes_spec, df_split_offchip_mispred_hermes_gapbs])\n",
    "\n",
    "df_split_offchip_mispred_hermes_mean = pandas.DataFrame({\n",
    "    'offchip_pred_l1d': [np.mean(df_split_offchip_mispred_hermes['offchip_pred_l1d'])],\n",
    "    'offchip_pred_l2c': [np.mean(df_split_offchip_mispred_hermes['offchip_pred_l2c'])],\n",
    "    'offchip_pred_l2c_llc': [np.mean(df_split_offchip_mispred_hermes['offchip_pred_l2c_llc'])],\n",
    "    'offchip_pred_dram': [np.mean(df_split_offchip_mispred_hermes['offchip_pred_dram'])],\n",
    "}, index=['AVG'])\n",
    "\n",
    "# df_split_offchip_mispred_hermes = pandas.concat([df_split_offchip_mispred_hermes, df_split_offchip_mispred_hermes_mean])\n",
    "\n",
    "display(df_split_offchip_mispred_hermes)\n",
    "display(df_split_offchip_mispred_hermes_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hit_miss_l1d = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hit_miss_l1d.tight_layout(pad=0)\n",
    "gs = GridSpec(nrows=1, ncols=5, figure=fig_hit_miss_l1d)\n",
    "\n",
    "ax_hit_miss_l1d, ax_hit_miss_l1d_mean = fig_hit_miss_l1d.add_subplot(\n",
    "    gs[0, :4]), fig_hit_miss_l1d.add_subplot(gs[0, 4:])\n",
    "xticklabels = df_split_offchip_mispred_hermes.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_split_offchip_mispred_hermes.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.05\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(0, len(xticklabels))\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "\n",
    "prev = np.array([0.0 for _ in range(len(df_split_offchip_mispred_hermes))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    ax_hit_miss_l1d.bar(index + (cat_spacing / 2),\n",
    "                        df_split_offchip_mispred_hermes[e],\n",
    "                        bottom=prev,\n",
    "                        edgecolor='black',\n",
    "                        linewidth=0.2,\n",
    "                        align='edge',\n",
    "                        label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += np.array(df_split_offchip_mispred_hermes[e].to_list())\n",
    "\n",
    "# ax_hit_miss_l1d.axvspan(xmin=0, xmax=len(spec_keys), color='black', alpha=1.0, zorder=-1)\n",
    "# ax_hit_miss_l1d.axvline(x=len(spec_keys) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "# ax_hit_miss_l1d.axvline(x=len(spec_keys) + len(gapbs_keys) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "\n",
    "\n",
    "ax_hit_miss_l1d.set_xticks(\n",
    "    [0, len(spec_keys) + 1, len(spec_keys) + len(gapbs_keys)])\n",
    "# ax_hit_miss_l1d.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_hit_miss_l1d.set_xticklabels(['SPEC', '', 'GAP'], fontsize=5)\n",
    "ax_hit_miss_l1d.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_hit_miss_l1d.set_axisbelow(True)\n",
    "\n",
    "ax_hit_miss_l1d.set_ylabel(\n",
    "    'Off-chip Prediction\\nOutcome (\\%)', fontsize=8)\n",
    "\n",
    "ax_hit_miss_l1d.tick_params(axis='both')\n",
    "ax_hit_miss_l1d.tick_params(labeltop=False)\n",
    "ax_hit_miss_l1d.tick_params(axis='x',\n",
    "                            which='both',\n",
    "                            bottom=True,\n",
    "                            top=False)\n",
    "\n",
    "ax_hit_miss_l1d.set_ylim([0.0, 100.0])\n",
    "\n",
    "# for idx, tick in enumerate(ax_hit_miss_l1d.xaxis.get_major_ticks()):\n",
    "#     if idx == 0 or idx == 2:\n",
    "#         tick.set_visible(False)\n",
    "#         tick.label1.set_visible(True)\n",
    "#     tick.label1.set_horizontalalignment('center')\n",
    "ax_hit_miss_l1d.xaxis.get_major_ticks(\n",
    ")[0].label1.set_horizontalalignment('left')\n",
    "ax_hit_miss_l1d.xaxis.get_majorticklabels()[0].set_x(len(spec_keys) / 2)\n",
    "ax_hit_miss_l1d.xaxis.get_major_ticks(\n",
    ")[-1].label1.set_horizontalalignment('right')\n",
    "ax_hit_miss_l1d.xaxis.get_majorticklabels(\n",
    ")[-1].set_x(len(gapbs_keys) + len(spec_keys) / 2)\n",
    "\n",
    "ax_hit_miss_l1d.legend(loc='upper center', edgecolor='white', fancybox=False, framealpha=0.0, ncol=4,\n",
    "           bbox_to_anchor=(0.5, 1.2),\n",
    "           fontsize=5\n",
    "           )\n",
    "\n",
    "# Plotting the mean in a seperate subplot.\n",
    "xticklabels = df_split_offchip_mispred_hermes_mean.index.to_list()\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "prev = np.array(\n",
    "    [0.0 for _ in range(len(df_split_offchip_mispred_hermes_mean))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_hit_miss_l1d_mean.bar(index + (cat_spacing / 2),\n",
    "                                    df_split_offchip_mispred_hermes_mean[e],\n",
    "                                    bottom=prev,\n",
    "                                    edgecolor='black',\n",
    "                                    linewidth=0.2,\n",
    "                                    align='edge',\n",
    "                                    label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += df_split_offchip_mispred_hermes_mean[e]\n",
    "\n",
    "ax_hit_miss_l1d_mean.set_ylim([0.0, 100.0])\n",
    "ax_hit_miss_l1d_mean.set_xticks(index)\n",
    "ax_hit_miss_l1d_mean.set_xticklabels([])\n",
    "ax_hit_miss_l1d_mean.bar_label(ax_hit_miss_l1d_mean.containers[-1], labels=[\n",
    "                               'AVG'], label_type='edge', rotation=0, fontsize=5, padding=3)\n",
    "ax_hit_miss_l1d_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_hit_miss_l1d_mean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_offchip_mispredictions.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_offchip_mispredictions.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useless_spec = {\n",
    "    'l2c': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['l2c'] for k in spec_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['llc'] for k in spec_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['dram'] for k in spec_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useless_spec = pandas.DataFrame(\n",
    "    dict_l1d_pref_useless_spec, columns=dict_l1d_pref_useless_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useless_spec))\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_pref_useless_spec.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_pref_useless_spec[df_l1d_pref_useless_spec.index != 'mean'].sort_values(\n",
    "#     by=df_l1d_pref_useless_spec.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_pref_useless_spec = pandas.concat(\n",
    "#     [df_tmp, df_l1d_pref_useless_spec[df_l1d_pref_useless_spec.index == 'mean']])\n",
    "\n",
    "# speedup_gapbs_keys = df_l1d_pref_useless_spec.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "# display(df_l1d_pref_useless_spec)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'l2c': 'L2C',\n",
    "    'llc': 'LLC',\n",
    "    'dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useless_gapbs = {\n",
    "    'l2c': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['l2c'] for k in gapbs_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['llc'] for k in gapbs_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['dram'] for k in gapbs_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useless_gapbs = pandas.DataFrame(\n",
    "    dict_l1d_pref_useless_gapbs, columns=dict_l1d_pref_useless_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useless_gapbs))\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_pref_useless_gapbs.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_pref_useless_gapbs[df_l1d_pref_useless_gapbs.index != 'mean'].sort_values(\n",
    "#     by=df_l1d_pref_useless_gapbs.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_pref_useless_gapbs = pandas.concat(\n",
    "#     [df_tmp, df_l1d_pref_useless_gapbs[df_l1d_pref_useless_gapbs.index == 'mean']])\n",
    "\n",
    "# speedup_gapbs_keys = df_l1d_pref_useless_gapbs.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "# display(df_l1d_pref_useless_gapbs)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'l2c': 'L2C',\n",
    "    'llc': 'LLC',\n",
    "    'dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1d_pref_useless = pandas.concat(\n",
    "    [df_l1d_pref_useless_spec, df_l1d_pref_useless_gapbs])\n",
    "\n",
    "df_l1d_pref_useless_mean = pandas.DataFrame({\n",
    "    'l2c': [np.mean(df_l1d_pref_useless['l2c'])],\n",
    "    'llc': [np.mean(df_l1d_pref_useless['llc'])],\n",
    "    'dram': [np.mean(df_l1d_pref_useless['dram'])],\n",
    "}, index=['AVG'])\n",
    "\n",
    "# df_l1d_pref_useless = pandas.concat([df_l1d_pref_useless, df_l1d_pref_useless_mean])\n",
    "\n",
    "display(df_l1d_pref_useless)\n",
    "display(df_l1d_pref_useless_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hit_miss_l1d = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hit_miss_l1d.tight_layout(pad=0)\n",
    "gs = GridSpec(nrows=1, ncols=5, figure=fig_hit_miss_l1d)\n",
    "\n",
    "ax_l1d_useless_loc, ax_l1d_useless_loc_mean = fig_hit_miss_l1d.add_subplot(\n",
    "    gs[0, :4]), fig_hit_miss_l1d.add_subplot(gs[0, 4:])\n",
    "ax_l1d_useless_loc.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_pref_useless.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_pref_useless.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useless))])\n",
    "bars = None\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useless_loc.bar(index + (cat_spacing / 2),\n",
    "                                  df_l1d_pref_useless[e],\n",
    "                                  bottom=prev,\n",
    "                                  edgecolor='black',\n",
    "                                  linewidth=0.2,\n",
    "                                  align='edge',\n",
    "                                  label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += np.array(df_l1d_pref_useless[e].to_list())\n",
    "\n",
    "ax_l1d_useless_loc.axvspan(xmin=0, xmax=len(\n",
    "    df_l1d_pref_useless_spec) + 1, facecolor='grey', alpha=0.25, zorder=-1)\n",
    "# ax_l1d_useless_loc.axvline(x=len(df_l1d_pref_useless_spec) + len(df_l1d_pref_useless_gapbs) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "\n",
    "# Annotating the 5th to last bar of the plot.\n",
    "ax_l1d_useless_loc.annotate(f'{prev[-4]:.2f}', (bars.patches[-4].get_x() + bars.patches[-4].get_width() / 2 - 3.5, 160\n",
    "                                                ), ha='center', va='center', textcoords='offset points', xytext=(0, 9), size=4)\n",
    "\n",
    "ax_l1d_useless_loc.set_xticks(index)\n",
    "# ax_l1d_useless_loc.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_l1d_useless_loc.set_xticklabels([])\n",
    "ax_l1d_useless_loc.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_l1d_useless_loc.set_axisbelow(True)\n",
    "\n",
    "ax_l1d_useless_loc.set_ylabel(\n",
    "    'Prefetches Per Kilo\\nInstructions (PPKI)', fontsize=8)\n",
    "\n",
    "ax_l1d_useless_loc.tick_params(axis='both')\n",
    "ax_l1d_useless_loc.tick_params(labeltop=False)\n",
    "ax_l1d_useless_loc.tick_params(axis='x',\n",
    "                               which='both',\n",
    "                               bottom=False,\n",
    "                               top=False)\n",
    "\n",
    "# ax_l1d_useless_loc.set_yscale('log')\n",
    "ax_l1d_useless_loc.set_ylim([0.0, 200.0])\n",
    "\n",
    "for tick in ax_l1d_useless_loc.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_l1d_useless_loc.legend(loc='upper center', edgecolor='white', fancybox=False, framealpha=0.0, ncol=3,\n",
    "                          bbox_to_anchor=(0.5, 1.2),\n",
    "                          fontsize=5\n",
    "                          )\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_l1d_useless_loc.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "ax_l1d_useless_loc.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "\n",
    "# Plotting the mean in a seperate subplot.\n",
    "xticklabels = df_l1d_pref_useless_mean.index.to_list()\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useless_mean))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useless_loc_mean.bar(index + (cat_spacing / 2),\n",
    "                                       df_l1d_pref_useless_mean[e],\n",
    "                                       bottom=prev,\n",
    "                                       edgecolor='black',\n",
    "                                       linewidth=0.2,\n",
    "                                       align='edge',\n",
    "                                       label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += df_l1d_pref_useless_mean[e]\n",
    "\n",
    "ax_l1d_useless_loc_mean.yaxis.set_major_locator(MultipleLocator(75))\n",
    "ax_l1d_useless_loc_mean.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_l1d_useless_loc_mean.yaxis.set_minor_locator(MultipleLocator(25))\n",
    "ax_l1d_useless_loc_mean.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "ax_l1d_useless_loc_mean.set_ylim([0.0, 75.0])\n",
    "ax_l1d_useless_loc_mean.set_xticks(index)\n",
    "ax_l1d_useless_loc_mean.set_xticklabels([])\n",
    "ax_l1d_useless_loc_mean.bar_label(ax_l1d_useless_loc_mean.containers[-1], labels=[\n",
    "                                  'AVG'], label_type='edge', rotation=0, fontsize=5, padding=3)\n",
    "ax_l1d_useless_loc_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_l1d_useless_loc_mean.grid(True, which='minor', color='grey',\n",
    "                             linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_l1d_useless_loc_mean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_l1d_pref_useless.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_l1d_pref_useless.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useful_spec = {\n",
    "    'l2c': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['l2c'] for k in spec_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['llc'] for k in spec_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['dram'] for k in spec_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useful_spec = pandas.DataFrame(\n",
    "    dict_l1d_pref_useful_spec, columns=dict_l1d_pref_useful_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useful_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useful_gapbs = {\n",
    "    'l2c': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['l2c'] for k in gapbs_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['llc'] for k in gapbs_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['dram'] for k in gapbs_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useful_gapbs = pandas.DataFrame(\n",
    "    dict_l1d_pref_useful_gapbs, columns=dict_l1d_pref_useful_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useful_gapbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1d_pref_useful = pandas.concat(\n",
    "    [df_l1d_pref_useful_spec, df_l1d_pref_useful_gapbs])\n",
    "\n",
    "df_l1d_pref_useful_mean = pandas.DataFrame({\n",
    "    'l2c': [np.mean(df_l1d_pref_useful['l2c'])],\n",
    "    'llc': [np.mean(df_l1d_pref_useful['llc'])],\n",
    "    'dram': [np.mean(df_l1d_pref_useful['dram'])],\n",
    "}, index=['AVG'])\n",
    "\n",
    "# df_l1d_pref_useful = pandas.concat([df_l1d_pref_useful, df_l1d_pref_useful_mean])\n",
    "\n",
    "display(df_l1d_pref_useful)\n",
    "display(df_l1d_pref_useful_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hit_miss_l1d = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hit_miss_l1d.tight_layout(pad=0)\n",
    "gs = GridSpec(nrows=1, ncols=5, figure=fig_hit_miss_l1d)\n",
    "\n",
    "ax_l1d_useful_loc, ax_l1d_useful_loc_mean = fig_hit_miss_l1d.add_subplot(\n",
    "    gs[0, :4]), fig_hit_miss_l1d.add_subplot(gs[0, 4:])\n",
    "ax_l1d_useful_loc.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_pref_useful.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_pref_useful.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useful))])\n",
    "bars = None\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useful_loc.bar(index + (cat_spacing / 2),\n",
    "                                  df_l1d_pref_useful[e],\n",
    "                                  bottom=prev,\n",
    "                                  edgecolor='black',\n",
    "                                  linewidth=0.2,\n",
    "                                  align='edge',\n",
    "                                  label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += np.array(df_l1d_pref_useful[e].to_list())\n",
    "\n",
    "ax_l1d_useful_loc.axvspan(xmin=0, xmax=len(\n",
    "    df_l1d_pref_useful_spec) + 1, facecolor='grey', alpha=0.25, zorder=-1)\n",
    "# ax_l1d_useful_loc.axvline(x=len(df_l1d_pref_useful_spec) + len(df_l1d_pref_useful_gapbs) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "\n",
    "# Annotating the 5th to last bar of the plot.\n",
    "ax_l1d_useful_loc.annotate(f'{prev[-4]:.2f}', (bars.patches[-4].get_x() + bars.patches[-4].get_width() / 2 - 3.5, 160\n",
    "                                                ), ha='center', va='center', textcoords='offset points', xytext=(0, 9), size=4)\n",
    "\n",
    "ax_l1d_useful_loc.set_xticks(index)\n",
    "# ax_l1d_useful_loc.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_l1d_useful_loc.set_xticklabels([])\n",
    "ax_l1d_useful_loc.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_l1d_useful_loc.set_axisbelow(True)\n",
    "\n",
    "ax_l1d_useful_loc.set_ylabel(\n",
    "    'Prefetches Per Kilo\\nInstructions (PPKI)', fontsize=8)\n",
    "\n",
    "ax_l1d_useful_loc.tick_params(axis='both')\n",
    "ax_l1d_useful_loc.tick_params(labeltop=False)\n",
    "ax_l1d_useful_loc.tick_params(axis='x',\n",
    "                               which='both',\n",
    "                               bottom=False,\n",
    "                               top=False)\n",
    "\n",
    "# ax_l1d_useful_loc.set_yscale('log')\n",
    "ax_l1d_useful_loc.set_ylim([0.0, 10.0])\n",
    "\n",
    "for tick in ax_l1d_useful_loc.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_l1d_useful_loc.legend(loc='upper center', edgecolor='white', fancybox=False, framealpha=0.0, ncol=3,\n",
    "                          bbox_to_anchor=(0.5, 1.2),\n",
    "                          fontsize=5\n",
    "                          )\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_l1d_useful_loc.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "ax_l1d_useful_loc.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "\n",
    "# Plotting the mean in a seperate subplot.\n",
    "xticklabels = df_l1d_pref_useful_mean.index.to_list()\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useful_mean))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useful_loc_mean.bar(index + (cat_spacing / 2),\n",
    "                                       df_l1d_pref_useful_mean[e],\n",
    "                                       bottom=prev,\n",
    "                                       edgecolor='black',\n",
    "                                       linewidth=0.2,\n",
    "                                       align='edge',\n",
    "                                       label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += df_l1d_pref_useful_mean[e]\n",
    "\n",
    "ax_l1d_useful_loc_mean.yaxis.set_major_locator(MultipleLocator(5))\n",
    "ax_l1d_useful_loc_mean.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_l1d_useful_loc_mean.yaxis.set_minor_locator(MultipleLocator(2.5))\n",
    "ax_l1d_useful_loc_mean.yaxis.set_minor_formatter('{x:.1f}')\n",
    "\n",
    "ax_l1d_useful_loc_mean.set_ylim([0.0, 5.0])\n",
    "ax_l1d_useful_loc_mean.set_xticks(index)\n",
    "ax_l1d_useful_loc_mean.set_xticklabels([])\n",
    "ax_l1d_useful_loc_mean.bar_label(ax_l1d_useful_loc_mean.containers[-1], labels=[\n",
    "                                  'AVG'], label_type='edge', rotation=0, fontsize=5, padding=3)\n",
    "ax_l1d_useful_loc_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_l1d_useful_loc_mean.grid(True, which='minor', color='grey',\n",
    "                             linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_l1d_useful_loc_mean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_l1d_pref_useful.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_ipcp_l1d_pref_useful.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for the Berti prefetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing results file containing data relative to simulations comparing designs using no prefetchers what so ever to designs using a prefetcher only in the L1D.\n",
    "raw_data = p.parse(\n",
    "    'results/micro23_04_07_23/', new_caches_parser, distill_cache_parser)\n",
    "raw_data_cpy = deepcopy(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different configurations used to build this plot.\n",
    "cl_baseline_config, config_list = \\\n",
    "    {'bin': 'baseline_cascade_lake_berti'}, [\n",
    "        {'bin': 'baseline_cascade_lake_berti_l1d_filtered_prefetcher'}, # 0\n",
    "        {'bin': 'baseline_cascade_lake_berti_double_l1d'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_spp_ppf'},\n",
    "\n",
    "        # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "        # WIP: This is now design related to the HPCA'30 submission.\n",
    "        {'bin': 'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis'}, # 4\n",
    "        {'bin': 'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_delayed_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_delayed_tlp'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_tlp_layered_core_l1d'},\n",
    "\n",
    "        # Using a design combining SPP-PPF and Hermes-O as a comparison point for prefetcher accuracy.\n",
    "        {'bin': 'baseline_cascade_lake_berti_spp_ppf_hermes_o'}, # 9\n",
    "        {'bin': 'baseline_cascade_lake_berti_iso_prefetcher'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_hermes_o_double'},\n",
    "        {'bin': 'baseline_cascade_lake_no_prefetchers'},\n",
    "\n",
    "        # Designs relative to the coverage computation.\n",
    "        {'bin': 'baseline_cascade_lake_spp_ppf'}, # 13\n",
    "        {'bin': 'baseline_cascade_lake_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_spp_ppf_hermes_o'},\n",
    "        {'bin': 'baseline_cascade_lake_tlp_layered_core_l1d_f20_-25'},\n",
    "        {'bin': 'baseline_cascade_lake_no_ipcp'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_block_prefs'},\n",
    "        {'bin': 'baseline_cascade_lake_berti_slp'},\n",
    "    ]\n",
    "\n",
    "# Isolating results set based on the given configurations.\n",
    "r_cl_base, r_list = \\\n",
    "    raw_data / cl_baseline_config, [\n",
    "        raw_data / e for e in config_list]\n",
    "\n",
    "temp_res_set = [r_cl_base]\n",
    "\n",
    "temp_res_set.extend(r_list)\n",
    "temp_res_set.append(raw_data_cpy / cl_baseline_config)\n",
    "\n",
    "# Normalizing...\n",
    "for e in temp_res_set:\n",
    "    print(e.sets[0].config)\n",
    "    normalize_llc_distill_cache(e.sets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res_set_gapbs = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_gapbs)\n",
    "                       for e in temp_res_set[1:]]\n",
    "final_res_set_spec = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_spec)\n",
    "                      for e in temp_res_set[1:]]\n",
    "final_res_set_spec06 = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_specs06)\n",
    "                        for e in temp_res_set[1:]]\n",
    "final_res_set_spec17 = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_specs17)\n",
    "                        for e in temp_res_set[1:]]\n",
    "final_res_set_ligra = [apply_manipulator_to_all(e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, only_ligra)\n",
    "                       for e in temp_res_set[1:]]\n",
    "final_res_set_all = [apply_manipulator_to_all(\n",
    "    e, apply_simpoint, temp_res_set[0].sets[0], simpoints_data, exclude_ligra) for e in temp_res_set[1:]]\n",
    "\n",
    "speedup_gapbs_keys = [e for e in final_res_set_gapbs[0].sets[0].keys()\n",
    "                      if e != 'mean']\n",
    "gapbs_keys = [e for e in final_res_set_gapbs[0].sets[0].keys()\n",
    "              if e != 'geomean']\n",
    "speedup_spec_keys = [e for e in final_res_set_spec[0].sets[0].keys()\n",
    "                     if e != 'mean']\n",
    "spec_keys = [e for e in final_res_set_spec[0].sets[0].keys()\n",
    "             if e != 'geomean']\n",
    "speedup_spec06_keys = [e for e in final_res_set_spec06[0].sets[0].keys()\n",
    "                       if e != 'mean']\n",
    "spec06_keys = [e for e in final_res_set_spec06[0].sets[0].keys()\n",
    "               if e != 'geomean']\n",
    "speedup_spec17_keys = [e for e in final_res_set_spec17[0].sets[0].keys()\n",
    "                       if e != 'mean']\n",
    "spec17_keys = [e for e in final_res_set_spec17[0].sets[0].keys()\n",
    "               if e != 'geomean']\n",
    "speedup_ligra_keys = [e for e in final_res_set_ligra[0].sets[0].keys()\n",
    "                      if e != 'mean']\n",
    "ligra_keys = [e for e in final_res_set_ligra[0].sets[0].keys()\n",
    "              if e != 'geomean']\n",
    "speedup_all_keys = [\n",
    "    e for e in final_res_set_all[0].sets[0].keys() if e != 'mean']\n",
    "all_keys = [\n",
    "    e for e in final_res_set_all[0].sets[0].keys() if e != 'geomean']\n",
    "\n",
    "\n",
    "workload_sets = [final_res_set_spec, final_res_set_gapbs, final_res_set_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    'baseline_cascade_lake_no_l1d_prefetcher': 'No Prefetcher',\n",
    "    'baseline_cascade_lake_l1d_filtered_prefetcher': 'TSP',\n",
    "    'baseline_cascade_lake_double_l1d': 'L1D 64KB',\n",
    "    'baseline_cascade_lake_hermes_o': 'Hermes',\n",
    "    'baseline_cascade_lake_hermes_o_no_l1d_prefetcher': 'Hermes no L1D Prefetcher',\n",
    "    'baseline_cascade_lake_spp_ppf': 'PPF',\n",
    "    'baseline_cascade_lake_topt': 'T-OPT',\n",
    "    'baseline_cascade_lake': 'Baseline',\n",
    "\n",
    "    # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "    'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis': 'Selective Delay Hermes',\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': 'TLP',\n",
    "\n",
    "    'baseline_cascade_lake_berti_delayed_hermes_o': 'Delayed Hermes',\n",
    "    'baseline_cascade_lake_berti_delayed_tlp': 'Delayed TSP',\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d': 'Selective Delay TSP',\n",
    "\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': 'Hermes + PPF',\n",
    "    'baseline_cascade_lake_berti_iso_prefetcher': '2xBerti',\n",
    "    'baseline_cascade_lake_berti_hermes_o_double': '2xHermes',\n",
    "    'baseline_cascade_lake_no_prefetchers': 'No Prefetchers',\n",
    "    'baseline_cascade_lake_berti': 'Baseline',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpkis_spec = {\n",
    "    'baseline_llc_mpki': [final_res_set_spec[-1].sets[0][e]['llc_mpki'] for e in spec_keys if e != 'mean'],\n",
    "}\n",
    "\n",
    "df_llc_mpki_spec = pandas.DataFrame(\n",
    "    dict_llc_mpkis_spec, columns=dict_llc_mpkis_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "df_llc_mpki_spec.sort_values(by='baseline_llc_mpki', inplace=True)\n",
    "\n",
    "# display(df_llc_mpki_spec)\n",
    "\n",
    "dict_llc_mpki_gapbs = {\n",
    "    'baseline_llc_mpki': [final_res_set_gapbs[-1].sets[0][e]['llc_mpki'] for e in gapbs_keys if e != 'mean'],\n",
    "}\n",
    "df_llc_mpki_gapbs = pandas.DataFrame(\n",
    "    dict_llc_mpki_gapbs, columns=dict_llc_mpki_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "df_llc_mpki_gapbs.sort_values(by='baseline_llc_mpki', inplace=True)\n",
    "\n",
    "# display(df_llc_mpki_gapbs)\n",
    "\n",
    "# Updating the keys with proper ordering.\n",
    "speedup_spec_keys, speedup_gapbs_keys = df_llc_mpki_spec.index.to_list(\n",
    "), df_llc_mpki_gapbs.index.to_list()\n",
    "spec_keys, gapbs_keys = df_llc_mpki_spec.index.to_list(\n",
    "), df_llc_mpki_gapbs.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sets, res_keys = [final_res_set_spec, final_res_set_gapbs], [\n",
    "    speedup_spec_keys, speedup_gapbs_keys]\n",
    "speedup_list, speedup_pref_list, speedup_all_keys = [], [], []\n",
    "\n",
    "dict_speedup = {\n",
    "    # 'baseline_cascade_lake_double_l1d': [],\n",
    "    'baseline_cascade_lake_spp_ppf': [],\n",
    "    'baseline_cascade_lake_hermes_o': [],\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': [],\n",
    "    'baseline_cascade_lake_berti_delayed_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_berti_delayed_tlp': [],\n",
    "\n",
    "    # WIP: Addition of improved designs for the MICRO'23 rebuttals.\n",
    "    # 'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis': [],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': [],\n",
    "    # 'baseline_cascade_lake_berti_iso_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_berti_hermes_o_double': [],\n",
    "    'baseline_cascade_lake_no_prefetchers': [],\n",
    "    'baseline_cascade_lake_berti_block_prefs': [],\n",
    "    'baseline_cascade_lake_berti_slp': [],\n",
    "}\n",
    "\n",
    "for set, keys in zip(res_sets, res_keys):\n",
    "    # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_double_l1d'].extend([set[1].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_spp_ppf'].extend(\n",
    "        [set[3].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_hermes_o'].extend(\n",
    "        [set[2].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_berti_spp_ppf_hermes_o'].extend(\n",
    "        [set[9].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_berti_delayed_hermes_o'].extend([set[6].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_berti_delayed_tlp'].extend([set[7].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "    # dict_speedup['baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_berti_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "        [set[5].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_berti_iso_prefetcher'].extend(\n",
    "    #     [set[10].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_speedup['baseline_cascade_lake_berti_hermes_o_double'].extend(\n",
    "    #     [set[11].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "        [set[12].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_berti_block_prefs'].extend(\n",
    "        [set[18].sets[0][k]['speedup'] for k in keys])\n",
    "    dict_speedup['baseline_cascade_lake_berti_slp'].extend(\n",
    "        [set[19].sets[0][k]['speedup'] for k in keys])\n",
    "\n",
    "    # Adding keys to the list.\n",
    "    speedup_all_keys.extend(keys)\n",
    "\n",
    "# for k, v in dict_speedup.items():\n",
    "#     dict_speedup[k] = sorted(v)\n",
    "\n",
    "df_speedup_hermes_o = pandas.DataFrame(\n",
    "    dict_speedup, columns=dict_speedup.keys(), index=speedup_all_keys)\n",
    "\n",
    "# df_tmp = df_speedup_hermes_o[df_speedup_hermes_o.index != 'mean'].sort_values(\n",
    "#     by=df_speedup_hermes_o.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_speedup_hermes_o = df_tmp\n",
    "\n",
    "df_speedup_hermes_o -= 1.0\n",
    "df_speedup_hermes_o *= 100.0\n",
    "\n",
    "# Creating a DataFrame containing the geo-means for the different benchmark suites.\n",
    "speedup_gmean_list, speedup_pref_gmean_list, gmean_keys = [s[0].sets[0]['geomean']['speedup']\n",
    "                                                           for s in [*res_sets, final_res_set_all]], \\\n",
    "    [s[0].sets[0]['geomean']['speedup']\n",
    "     for s in [*res_sets, final_res_set_all]], \\\n",
    "    ['ALL']\n",
    "\n",
    "df_speedup_gmean = pandas.DataFrame({\n",
    "    # 'baseline_cascade_lake_ipcp': speedup_pref_gmean_list,\n",
    "    # 'baseline_cascade_lake_ipcp_hermes_o': speedup_gmean_list,\n",
    "    # 'baseline_cascade_lake_double_l1d': [s[1].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_spp_ppf': gmean(df_speedup_hermes_o['baseline_cascade_lake_spp_ppf'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    'baseline_cascade_lake_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_hermes_o'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_spp_ppf_hermes_o'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[0].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_berti_delayed_hermes_o': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_delayed_hermes_o'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[0].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_berti_delayed_tlp': [s[7].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "\n",
    "    # 'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis': [s[4].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [s[8].sets[0]['geomean']['speedup'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    # 'baseline_cascade_lake_berti_iso_prefetcher': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_iso_prefetcher'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    # 'baseline_cascade_lake_berti_hermes_o_double': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_hermes_o_double'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    'baseline_cascade_lake_no_prefetchers': gmean(df_speedup_hermes_o['baseline_cascade_lake_no_prefetchers'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    'baseline_cascade_lake_berti_block_prefs': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_block_prefs'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "    'baseline_cascade_lake_berti_slp': gmean(df_speedup_hermes_o['baseline_cascade_lake_berti_slp'] / 100.0 + 1.0, nan_policy='omit'),\n",
    "}, index=gmean_keys)\n",
    "\n",
    "df_speedup_gmean -= 1.0\n",
    "df_speedup_gmean *= 100.0\n",
    "\n",
    "labels_dict.update({\n",
    "    # 'baseline_cascade_lake_ipcp': 'IPCP',\n",
    "    'baseline_cascade_lake_ipcp_hermes_o': 'Hermes-O',\n",
    "    'baseline_cascade_lake_berti_block_prefs': 'Block Prefs',\n",
    "    'baseline_cascade_lake_berti_slp': 'SLP',\n",
    "})\n",
    "\n",
    "display(df_speedup_hermes_o)\n",
    "display(df_speedup_gmean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hermes_o_speedup = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hermes_o_speedup.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 5, figure=fig_hermes_o_speedup)\n",
    "\n",
    "ax_hermes_o_speedup, ax_hermes_o_gmean = fig_hermes_o_speedup.add_subplot(\n",
    "    gs[0, :4]), fig_hermes_o_speedup.add_subplot(gs[0, 4:])\n",
    "ax_hermes_o_speedup.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_speedup_hermes_o.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_speedup_hermes_o.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.05\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "# for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "#     ax_hermes_o_speedup.bar(index + i * (bar_width) + (cat_spacing / 2),\n",
    "#                     df_speedup_hermes_o[e], width=bar_width, edgecolor='black', linewidth=0.2, align='edge', label=labels_dict[e], color=c)\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    ax_hermes_o_speedup.scatter(index + i * (bar_width) + (cat_spacing / 2),\n",
    "                                df_speedup_hermes_o[e],\n",
    "                                s=5,\n",
    "                                marker=m,\n",
    "                                edgecolor='black',\n",
    "                                linewidths=0.5,\n",
    "                                # width=bar_width, edgecolor='black', linewidth=0.2, align='edge',\n",
    "                                label=labels_dict[e], color=c)\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_hermes_o_speedup.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, -15), ha='center', va='center', size=7)\n",
    "ax_hermes_o_speedup.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, -15), ha='center', va='center', size=7)\n",
    "\n",
    "ax_hermes_o_speedup.axvspan(xmin=0, xmax=len(\n",
    "    spec_keys) + 1, color='grey', alpha=0.25, zorder=-1)\n",
    "\n",
    "ax_hermes_o_speedup.set_xticks(index)\n",
    "# ax_hermes_o_speedup.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_hermes_o_speedup.set_xticklabels([])\n",
    "ax_hermes_o_speedup.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_hermes_o_speedup.grid(True, which='minor', color='grey',\n",
    "                         linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_hermes_o_speedup.set_axisbelow(True)\n",
    "\n",
    "ax_hermes_o_speedup.set_ylabel(r'Speedup (\\%)', fontsize=8)\n",
    "\n",
    "ax_hermes_o_speedup.tick_params(axis='both')\n",
    "ax_hermes_o_speedup.tick_params(labeltop=False)\n",
    "ax_hermes_o_speedup.tick_params(axis='x',\n",
    "                                which='both',\n",
    "                                bottom=False,\n",
    "                                top=False)\n",
    "\n",
    "ax_hermes_o_speedup.set_ylim([-20.0, 40.0])\n",
    "\n",
    "ax_hermes_o_speedup.yaxis.set_major_locator(MultipleLocator(40))\n",
    "ax_hermes_o_speedup.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_hermes_o_speedup.yaxis.set_minor_locator(MultipleLocator(20))\n",
    "ax_hermes_o_speedup.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "for tick in ax_hermes_o_speedup.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_hermes_o_speedup.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0, ncol=2,\n",
    "                           fontsize=5\n",
    "                           )\n",
    "\n",
    "# Working on the second subplot that will contain the mean for each benchmark suite.\n",
    "xticklabels = gmean_keys\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    ax_hermes_o_gmean.bar(index + i * bar_width + cat_spacing / 2,\n",
    "                          df_speedup_gmean[e], width=bar_width, linewidth=0.2, edgecolor='black', align='edge', label=labels_dict[e], color=c)\n",
    "    \n",
    "for b, k in zip(ax_hermes_o_gmean.patches, key_list):\n",
    "    print(k)\n",
    "    ax_hermes_o_gmean.annotate(labels_dict[k], (b.get_x() + b.get_width() / 2, 10), size=4, rotation=90,\n",
    "                            #    ha='center',\n",
    "                               # va='center',\n",
    "                               # xytext=(0, 10), textcoords='offset points'\n",
    "                               )\n",
    "\n",
    "ax_hermes_o_gmean.set_xticks(index)\n",
    "ax_hermes_o_gmean.set_xticklabels([])\n",
    "# ax_hermes_o_gmean.bar_label(ax_hermes_o_gmean.containers[-1], labels=gmean_keys, label_type='edge', rotation=90, fontsize=5, padding=3)\n",
    "ax_hermes_o_gmean.set_ylim([0.0, 25.0])\n",
    "ax_hermes_o_gmean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_hermes_o_gmean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_speedup_alt.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_speedup_alt.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sets, res_keys = [final_res_set_spec,\n",
    "                      final_res_set_gapbs], [spec_keys, gapbs_keys]\n",
    "dram_trans_pref_list, dram_trans_list, dram_trans_all_keys = [], [], []\n",
    "\n",
    "# for set, keys in zip(res_sets, res_keys):\n",
    "#     # dram_trans_pref_list.extend([set[0].sets[0][k]['dram']['transactions'] /\n",
    "#     #                        set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "#     dram_trans_list.extend([set[0].sets[0][k]['dram']['transactions'] /\n",
    "#                            set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "#     # Adding keys to the list.\n",
    "#     dram_trans_all_keys.extend(keys)\n",
    "\n",
    "# dict_dram_trans = {\n",
    "#     # 'baseline_cascade_lake_ipcp': dram_trans_pref_list,\n",
    "#     'baseline_cascade_lake_ipcp_hermes_o': dram_trans_list,\n",
    "# }\n",
    "\n",
    "dict_dram_trans = {\n",
    "    # 'baseline_cascade_lake_double_l1d': [],\n",
    "    'baseline_cascade_lake_spp_ppf': [],\n",
    "    'baseline_cascade_lake_hermes_o': [],\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_berti_delayed_hermes_o': [],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [],\n",
    "    # 'baseline_cascade_lake_berti_delayed_tlp': [],\n",
    "\n",
    "    # 'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis': [],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': [],\n",
    "    # 'baseline_cascade_lake_berti_hermes_o_double': [],\n",
    "    # 'baseline_cascade_lake_no_prefetchers': [],\n",
    "}\n",
    "\n",
    "for set, keys in zip(res_sets, res_keys):\n",
    "    # speedup_pref_list.extend([set[0].sets[0][k]['speedup'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_double_l1d'].extend([set[1].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_spp_ppf'].extend(\n",
    "        [set[3].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_hermes_o'].extend(\n",
    "        [set[2].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_berti_spp_ppf_hermes_o'].extend(\n",
    "        [set[9].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_l1d_filtered_prefetcher'].extend([set[0].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_berti_delayed_hermes_o'].extend([set[6].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_berti_delayed_tlp'].extend([set[7].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "    # dict_dram_trans['baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis'].extend([set[4].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_berti_tlp_layered_core_l1d'].extend([set[8].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    dict_dram_trans['baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25'].extend(\n",
    "        [set[5].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_berti_hermes_o_double'].extend(\n",
    "    #     [set[11].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "    # dict_dram_trans['baseline_cascade_lake_no_prefetchers'].extend(\n",
    "    #     [set[12].sets[0][k]['dram']['transactions'] / set[-1].sets[0][k]['dram']['transactions'] for k in keys])\n",
    "\n",
    "    # Adding keys to the list.\n",
    "    dram_trans_all_keys.extend(keys)\n",
    "\n",
    "# for k, v in dict_dram_trans.items():\n",
    "#     dict_dram_trans[k] = sorted(v)\n",
    "\n",
    "df_dram_trans = pandas.DataFrame(\n",
    "    dict_dram_trans, columns=dict_dram_trans.keys(), index=dram_trans_all_keys)\n",
    "\n",
    "df_dram_trans -= 1.0\n",
    "df_dram_trans *= 100.0\n",
    "\n",
    "# df_tmp = df_dram_trans[df_dram_trans.index != 'mean'].sort_values(\n",
    "#     by=df_dram_trans.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_dram_trans = df_tmp\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_dram_trans.sort_values(\n",
    "#     by='mean', axis='columns', inplace=True, ascending=True)\n",
    "# df_tmp = df_dram_trans[df_dram_trans.index != 'mean'].sort_values(\n",
    "#     by=df_dram_trans.columns.to_list()[0], axis='rows', inplace=False)\n",
    "# df_dram_trans = pandas.concat(\n",
    "#     [df_tmp, df_dram_trans[df_dram_trans.index == 'mean']])\n",
    "\n",
    "# Creating a DataFrame containing the means for the different benchmark suites.\n",
    "dram_trans_pref_mean_list, dram_trans_mean_list, mean_keys = [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]], \\\n",
    "    [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions']\n",
    "     for s in [*res_sets, final_res_set_all]], ['ALL']\n",
    "\n",
    "df_dram_trans_mean = pandas.DataFrame({\n",
    "    # 'baseline_cascade_lake_ipcp': dram_trans_pref_mean_list,\n",
    "    # 'baseline_cascade_lake_double_l1d': [s[1].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_spp_ppf': np.nanmean(df_dram_trans['baseline_cascade_lake_spp_ppf']),\n",
    "    'baseline_cascade_lake_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_hermes_o']),\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_berti_spp_ppf_hermes_o']),\n",
    "    # 'baseline_cascade_lake_berti_delayed_hermes_o': np.nanmean(df_dram_trans['baseline_cascade_lake_berti_delayed_hermes_o']),\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[0].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_berti_delayed_tlp': [s[7].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "\n",
    "    # 'baseline_cascade_lake_berti_tlp_core_l1d_-15_-35_bis': [s[4].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [s[8].sets[0]['mean']['dram']['transactions'] / s[-1].sets[0]['mean']['dram']['transactions'] for s in [*res_sets, final_res_set_all]],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': np.nanmean(df_dram_trans['baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25']),\n",
    "    # 'baseline_cascade_lake_berti_hermes_o_double': np.nanmean(df_dram_trans['baseline_cascade_lake_berti_hermes_o_double']),\n",
    "    # 'baseline_cascade_lake_no_prefetchers': np.nanmean(df_dram_trans['baseline_cascade_lake_no_prefetchers']),\n",
    "}, index=mean_keys)\n",
    "\n",
    "# df_dram_trans_mean -= 1.0\n",
    "# df_dram_trans_mean *= 100.0\n",
    "# del(df_tmp)\n",
    "\n",
    "# Concatenating the 50 highest values with the means per benchmark suites.\n",
    "# df_dram_trans = pandas.concat([df_tmp, df_dram_trans_mean])\n",
    "\n",
    "display(np.nanmean(df_dram_trans['baseline_cascade_lake_spp_ppf']))\n",
    "display(df_dram_trans_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hermes_o_dram_trans = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hermes_o_dram_trans.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 5, figure=fig_hermes_o_dram_trans)\n",
    "\n",
    "ax_hermes_o_dram_trans, ax_hermes_o_dram_trans_mean = fig_hermes_o_dram_trans.add_subplot(\n",
    "    gs[0, :4]), fig_hermes_o_dram_trans.add_subplot(gs[0, 4:])\n",
    "ax_hermes_o_dram_trans.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_dram_trans.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_dram_trans.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.05\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "# for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "#     ax_hermes_o_dram_trans.bar(index + i * (bar_width) + (cat_spacing / 2),\n",
    "#                     df_speedup_hermes_o[e], width=bar_width, edgecolor='black', linewidth=0.2, align='edge', label=labels_dict[e], color=c)\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    ax_hermes_o_dram_trans.scatter(index + i * (bar_width) + (cat_spacing / 2),\n",
    "                                   df_dram_trans[e],\n",
    "                                   s=5,\n",
    "                                   marker=m,\n",
    "                                   edgecolor='black',\n",
    "                                   linewidths=0.5,\n",
    "                                   # width=bar_width, edgecolor='black', linewidth=0.2, align='edge',\n",
    "                                   label=labels_dict[e], color=c)\n",
    "\n",
    "ax_hermes_o_dram_trans.axvspan(xmin=0, xmax=len(\n",
    "    spec_keys) + 1, color='grey', alpha=0.25, zorder=-1)\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_hermes_o_dram_trans.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, -75), ha='center', va='center', size=7)\n",
    "ax_hermes_o_dram_trans.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, -75), ha='center', va='center', size=7)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_xticks(index)\n",
    "# ax_hermes_o_dram_trans.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_hermes_o_dram_trans.set_xticklabels([])\n",
    "ax_hermes_o_dram_trans.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_hermes_o_dram_trans.grid(True, which='minor', color='grey',\n",
    "                            linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_hermes_o_dram_trans.set_axisbelow(True)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_ylabel(\n",
    "    'Increase DRAM\\nTransactions (\\%)', fontsize=8)\n",
    "\n",
    "ax_hermes_o_dram_trans.tick_params(axis='both')\n",
    "ax_hermes_o_dram_trans.tick_params(labeltop=False)\n",
    "ax_hermes_o_dram_trans.tick_params(axis='x',\n",
    "                                   which='both',\n",
    "                                   bottom=False,\n",
    "                                   top=False)\n",
    "\n",
    "ax_hermes_o_dram_trans.set_ylim([-100.0, 100.0])\n",
    "\n",
    "ax_hermes_o_dram_trans.yaxis.set_major_locator(MultipleLocator(100))\n",
    "ax_hermes_o_dram_trans.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_hermes_o_dram_trans.yaxis.set_minor_locator(MultipleLocator(50))\n",
    "ax_hermes_o_dram_trans.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "for tick in ax_hermes_o_dram_trans.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_hermes_o_dram_trans.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0, ncol=2,\n",
    "                              fontsize=5\n",
    "                              )\n",
    "\n",
    "# Working on the second subplot that will contain the mean for each benchmark suite.\n",
    "xticklabels = mean_keys\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    ax_hermes_o_dram_trans_mean.bar(index + i * bar_width + cat_spacing / 2,\n",
    "                                    df_dram_trans_mean[e], width=bar_width, linewidth=0.2, edgecolor='black', align='edge', label=labels_dict[e], color=c)\n",
    "\n",
    "for b, k in zip(ax_hermes_o_dram_trans_mean.patches, key_list):\n",
    "    print(k)\n",
    "    ax_hermes_o_dram_trans_mean.annotate(labels_dict[k], (b.get_x() + b.get_width() / 2, 18.5), size=3.5, rotation=90,\n",
    "                                         #    ha='center',\n",
    "                                         # va='center',\n",
    "                                         # xytext=(0, 10), textcoords='offset points'\n",
    "                                         )\n",
    "\n",
    "ax_hermes_o_dram_trans_mean.set_xticks(index)\n",
    "ax_hermes_o_dram_trans_mean.set_xticklabels([])\n",
    "# ax_hermes_o_dram_trans_mean.bar_label(ax_hermes_o_dram_trans_mean.containers[1], labels=gmean_keys, label_type='edge', rotation=90, fontsize=5, padding=3)\n",
    "ax_hermes_o_dram_trans_mean.set_ylim([-17.5, 60.0])\n",
    "ax_hermes_o_dram_trans_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_hermes_o_dram_trans_mean.grid(True, which='minor', color='grey',\n",
    "                            linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_hermes_o_dram_trans_mean.set_axisbelow(True)\n",
    "ax_hermes_o_dram_trans_mean.set_axisbelow(True)\n",
    "ax_hermes_o_dram_trans_mean.tick_params(axis='y', which='minor', labelsize=7.5)\n",
    "\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_major_locator(MultipleLocator(60))\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_major_formatter('{x:.0f}')\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_minor_locator(MultipleLocator(15))\n",
    "ax_hermes_o_dram_trans_mean.yaxis.set_minor_formatter('{x:.0f}')\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_dram_transactions_alt.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_dram_transactions_alt.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_accuracy = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': [s[9].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['l1d_prefetcher']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_l1d_prefetcher': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_l1d_accuracy = pandas.DataFrame(\n",
    "    dict_l1d_accuracy, columns=dict_l1d_accuracy.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "df_l1d_accuracy *= 100.0\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_accuracy.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_accuracy[df_l1d_accuracy.index != 'geomean'].sort_values(\n",
    "#     by=df_l1d_accuracy.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_accuracy = pandas.concat(\n",
    "#     [df_tmp, df_l1d_accuracy[df_l1d_accuracy.index == 'geomean']])\n",
    "\n",
    "display(df_l1d_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the actual plotting material.\n",
    "fig_l1d_pref_accuracy = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_l1d_pref_accuracy.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 1, figure=fig_l1d_pref_accuracy)\n",
    "\n",
    "fig_l1d_pref_accuracy = fig_l1d_pref_accuracy.add_subplot(\n",
    "    gs[:])\n",
    "fig_l1d_pref_accuracy.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_accuracy.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_accuracy.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based_2k_entries', 'hermes_o_pc_based', 'popet_o', 'hermes_o_perfect']\n",
    "\n",
    "cat_spacing = 0.1\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    fig_l1d_pref_accuracy.bar(index + (i - 1) * (bar_width),\n",
    "                              df_l1d_accuracy[e], width=bar_width, edgecolor='black', linewidth=0.2, align='center', label=labels_dict[e], color=c)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_xticks(index)\n",
    "fig_l1d_pref_accuracy.set_xticklabels(xticklabels, rotation=0)\n",
    "# fig_l1d_pref_accuracy.set_xticklabels([])\n",
    "fig_l1d_pref_accuracy.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "fig_l1d_pref_accuracy.set_axisbelow(True)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_ylabel(r'Accuracy (\\%)')\n",
    "\n",
    "fig_l1d_pref_accuracy.tick_params(axis='both')\n",
    "fig_l1d_pref_accuracy.tick_params(labeltop=False)\n",
    "\n",
    "fig_l1d_pref_accuracy.set_ylim([0, 100.0])\n",
    "\n",
    "fig_l1d_pref_accuracy.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0,\n",
    "                             ncol=3,\n",
    "                             fontsize=5,\n",
    "                             #    labelspacing=1.0,\n",
    "                             #    bbox_to_anchor=(0, 0.925, 1, 0.25),\n",
    "                             #    mode='expand'\n",
    "                             )\n",
    "\n",
    "for tick in fig_l1d_pref_accuracy.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('center')\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_l1d_prefetcher_accuracy.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_l1d_prefetcher_accuracy.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_coverage = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_berti': [s[-1].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_berti_spp_ppf_hermes_o': [s[9].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_berti_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_berti_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['llc_mpki'] / s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_l1d_coverage = pandas.DataFrame(\n",
    "    dict_l1d_coverage, columns=dict_l1d_coverage.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "df_l1d_coverage = 1.0 - df_l1d_coverage\n",
    "df_l1d_coverage *= 100.0\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_coverage.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_coverage[df_l1d_coverage.index != 'geomean'].sort_values(\n",
    "#     by=df_l1d_coverage.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_coverage = pandas.concat(\n",
    "#     [df_tmp, df_l1d_coverage[df_l1d_coverage.index == 'geomean']])\n",
    "\n",
    "display(df_l1d_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpki = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp': [s[-1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[1].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[2].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[9].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[5].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_llc_mpki = pandas.DataFrame(\n",
    "    dict_llc_mpki, columns=dict_llc_mpki.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "display(df_llc_mpki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_llc_mpki = {\n",
    "    # 'baseline_cascade_lake': [s[-1].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp': [s[17].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_spp_ppf': [s[13].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_hermes_o': [s[14].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_spp_ppf_hermes_o': [s[15].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_l1d_filtered_prefetcher': [s[3].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_ipcp_tlp_layered_core_l1d': [s[8].sets[0]['mean']['l1d_misses']['accuracy'] for s in workload_sets],\n",
    "    'baseline_cascade_lake_ipcp_tlp_layered_core_l1d_f20_-25': [s[16].sets[0]['mean']['llc_mpki'] for s in workload_sets],\n",
    "    # 'baseline_cascade_lake_hermes_o_no_llc_mpki': [(s[6].sets[0]['geomean']['speedup'] - 1.0) * 100.0 for s in speedup_all_keys],\n",
    "}\n",
    "\n",
    "df_llc_mpki = pandas.DataFrame(\n",
    "    dict_llc_mpki, columns=dict_llc_mpki.keys(), index=['SPEC', 'GAP', 'ALL'])\n",
    "\n",
    "display(df_llc_mpki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the actual plotting material.\n",
    "fig_l1d_pref_coverage = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_l1d_pref_coverage.tight_layout(pad=0)\n",
    "gs = GridSpec(1, 1, figure=fig_l1d_pref_coverage)\n",
    "\n",
    "fig_l1d_pref_coverage = fig_l1d_pref_coverage.add_subplot(\n",
    "    gs[:])\n",
    "fig_l1d_pref_coverage.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_coverage.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_coverage.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based_2k_entries', 'hermes_o_pc_based', 'popet_o', 'hermes_o_perfect']\n",
    "\n",
    "cat_spacing = 0.1\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list), endpoint=True))\n",
    "\n",
    "for i, (e, c) in enumerate(zip(key_list, colors)):\n",
    "    fig_l1d_pref_coverage.bar(index + (i - 1) * (bar_width),\n",
    "                              df_l1d_coverage[e], width=bar_width, edgecolor='black', linewidth=0.2, align='center', label=labels_dict[e], color=c)\n",
    "\n",
    "fig_l1d_pref_coverage.set_xticks(index)\n",
    "fig_l1d_pref_coverage.set_xticklabels(xticklabels, rotation=0)\n",
    "# fig_l1d_pref_coverage.set_xticklabels([])\n",
    "fig_l1d_pref_coverage.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "fig_l1d_pref_coverage.set_axisbelow(True)\n",
    "\n",
    "fig_l1d_pref_coverage.set_ylabel('LLC MPKI\\nReduction (\\%)')\n",
    "\n",
    "fig_l1d_pref_coverage.tick_params(axis='both')\n",
    "fig_l1d_pref_coverage.tick_params(labeltop=False)\n",
    "\n",
    "fig_l1d_pref_coverage.set_ylim([-5.0, 30.0])\n",
    "\n",
    "fig_l1d_pref_coverage.legend(loc='upper left', edgecolor='white', fancybox=False, framealpha=0.0,\n",
    "                             ncol=4,\n",
    "                             fontsize=5,\n",
    "                             #    labelspacing=1.0,\n",
    "                             #    bbox_to_anchor=(0, 0.925, 1, 0.25),\n",
    "                             #    mode='expand'\n",
    "                             )\n",
    "\n",
    "for tick in fig_l1d_pref_coverage.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('center')\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_l1d_prefetcher_coverage.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_evaluation_l1d_prefetcher_coverage.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useless_spec = {\n",
    "    'l2c': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['l2c'] for k in spec_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['llc'] for k in spec_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useless']['dram'] for k in spec_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useless_spec = pandas.DataFrame(\n",
    "    dict_l1d_pref_useless_spec, columns=dict_l1d_pref_useless_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_pref_useless_spec.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_pref_useless_spec[df_l1d_pref_useless_spec.index != 'mean'].sort_values(\n",
    "#     by=df_l1d_pref_useless_spec.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_pref_useless_spec = pandas.concat(\n",
    "#     [df_tmp, df_l1d_pref_useless_spec[df_l1d_pref_useless_spec.index == 'mean']])\n",
    "\n",
    "# speedup_gapbs_keys = df_l1d_pref_useless_spec.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "display(df_l1d_pref_useless_spec)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'l2c': 'L2C',\n",
    "    'llc': 'LLC',\n",
    "    'dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useless_gapbs = {\n",
    "    'l2c': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['l2c'] for k in gapbs_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['llc'] for k in gapbs_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useless']['dram'] for k in gapbs_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useless_gapbs = pandas.DataFrame(\n",
    "    dict_l1d_pref_useless_gapbs, columns=dict_l1d_pref_useless_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "# # Sorting by geomean speed-up.\n",
    "# df_l1d_pref_useless_gapbs.sort_values(\n",
    "#     by='geomean', axis='columns', inplace=True)\n",
    "# df_tmp = df_l1d_pref_useless_gapbs[df_l1d_pref_useless_gapbs.index != 'mean'].sort_values(\n",
    "#     by=df_l1d_pref_useless_gapbs.columns.to_list()[-1], axis='rows', inplace=False)\n",
    "# df_l1d_pref_useless_gapbs = pandas.concat(\n",
    "#     [df_tmp, df_l1d_pref_useless_gapbs[df_l1d_pref_useless_gapbs.index == 'mean']])\n",
    "\n",
    "# speedup_gapbs_keys = df_l1d_pref_useless_gapbs.index.to_list()\n",
    "# gapbs_keys = speedup_gapbs_keys[:-1] + ['mean']\n",
    "\n",
    "display(df_l1d_pref_useless_gapbs)\n",
    "\n",
    "# Labels for the plots.\n",
    "labels_dict = {\n",
    "    'l2c': 'L2C',\n",
    "    'llc': 'LLC',\n",
    "    'dram': 'DRAM',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1d_pref_useless = pandas.concat(\n",
    "    [df_l1d_pref_useless_spec, df_l1d_pref_useless_gapbs])\n",
    "\n",
    "df_l1d_pref_useless_mean = pandas.DataFrame({\n",
    "    'l2c': [np.mean(df_l1d_pref_useless['l2c'])],\n",
    "    'llc': [np.mean(df_l1d_pref_useless['llc'])],\n",
    "    'dram': [np.mean(df_l1d_pref_useless['dram'])],\n",
    "}, index=['AVG'])\n",
    "\n",
    "# df_l1d_pref_useless = pandas.concat([df_l1d_pref_useless, df_l1d_pref_useless_mean])\n",
    "\n",
    "display(df_l1d_pref_useless)\n",
    "display(df_l1d_pref_useless_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hit_miss_l1d = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hit_miss_l1d.tight_layout(pad=0)\n",
    "gs = GridSpec(nrows=1, ncols=5, figure=fig_hit_miss_l1d)\n",
    "\n",
    "ax_l1d_useless_loc, ax_l1d_useless_loc_mean = fig_hit_miss_l1d.add_subplot(\n",
    "    gs[0, :4]), fig_hit_miss_l1d.add_subplot(gs[0, 4:])\n",
    "ax_l1d_useless_loc.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_pref_useless.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_pref_useless.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useless))])\n",
    "bars = None\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useless_loc.bar(index + (cat_spacing / 2),\n",
    "                                  df_l1d_pref_useless[e],\n",
    "                                  bottom=prev,\n",
    "                                  edgecolor='black',\n",
    "                                  linewidth=0.2,\n",
    "                                  align='edge',\n",
    "                                  label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += np.array(df_l1d_pref_useless[e].to_list())\n",
    "\n",
    "ax_l1d_useless_loc.axvspan(xmin=0, xmax=len(\n",
    "    df_l1d_pref_useless_spec) + 1, facecolor='grey', alpha=0.25, zorder=-1)\n",
    "# ax_l1d_useless_loc.axvline(x=len(df_l1d_pref_useless_spec) + len(df_l1d_pref_useless_gapbs) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "\n",
    "# Annotating the 5th to last bar of the plot.\n",
    "ax_l1d_useless_loc.annotate(f'{prev[-4]:.2f}', (bars.patches[-4].get_x() + bars.patches[-4].get_width() / 2 - 3.5, 170\n",
    "                                                ), ha='center', va='center', textcoords='offset points', xytext=(0, 9), size=4)\n",
    "\n",
    "ax_l1d_useless_loc.set_xticks(index)\n",
    "# ax_l1d_useless_loc.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_l1d_useless_loc.set_xticklabels([])\n",
    "ax_l1d_useless_loc.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_l1d_useless_loc.set_axisbelow(True)\n",
    "\n",
    "ax_l1d_useless_loc.set_ylabel(\n",
    "    'Prefetches Per Kilo\\nInstructions (PPKI)', fontsize=8)\n",
    "\n",
    "ax_l1d_useless_loc.tick_params(axis='both')\n",
    "ax_l1d_useless_loc.tick_params(labeltop=False)\n",
    "ax_l1d_useless_loc.tick_params(axis='x',\n",
    "                               which='both',\n",
    "                               bottom=False,\n",
    "                               top=False)\n",
    "\n",
    "# ax_l1d_useless_loc.set_yscale('log')\n",
    "ax_l1d_useless_loc.set_ylim([0.0, 30.0])\n",
    "\n",
    "for tick in ax_l1d_useless_loc.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_l1d_useless_loc.legend(loc='upper center', edgecolor='white', fancybox=False, framealpha=0.0, ncol=3,\n",
    "                          bbox_to_anchor=(0.5, 1.2),\n",
    "                          fontsize=5\n",
    "                          )\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_l1d_useless_loc.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, 25), ha='center', va='center', size=7)\n",
    "ax_l1d_useless_loc.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, 25), ha='center', va='center', size=7)\n",
    "\n",
    "# Plotting the mean in a seperate subplot.\n",
    "xticklabels = df_l1d_pref_useless_mean.index.to_list()\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useless_mean))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useless_loc_mean.bar(index + (cat_spacing / 2),\n",
    "                                       df_l1d_pref_useless_mean[e],\n",
    "                                       bottom=prev,\n",
    "                                       edgecolor='black',\n",
    "                                       linewidth=0.2,\n",
    "                                       align='edge',\n",
    "                                       label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += df_l1d_pref_useless_mean[e]\n",
    "\n",
    "ax_l1d_useless_loc_mean.set_ylim([0.0, 15.0])\n",
    "ax_l1d_useless_loc_mean.set_xticks(index)\n",
    "ax_l1d_useless_loc_mean.set_xticklabels([])\n",
    "ax_l1d_useless_loc_mean.bar_label(ax_l1d_useless_loc_mean.containers[-1], labels=[\n",
    "                                  'AVG'], label_type='edge', rotation=0, fontsize=5, padding=3)\n",
    "ax_l1d_useless_loc_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_l1d_useless_loc_mean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_l1d_pref_useless.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_l1d_pref_useless.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useful_spec = {\n",
    "    'l2c': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['l2c'] for k in spec_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['llc'] for k in spec_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_spec[-1].sets[0][k]['l1d_prefetcher']['useful']['dram'] for k in spec_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useful_spec = pandas.DataFrame(\n",
    "    dict_l1d_pref_useful_spec, columns=dict_l1d_pref_useful_spec.keys(), index=[k for k in spec_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useful_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l1d_pref_useful_gapbs = {\n",
    "    'l2c': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['l2c'] for k in gapbs_keys if k != 'mean'],\n",
    "    'llc': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['llc'] for k in gapbs_keys if k != 'mean'],\n",
    "    'dram': [final_res_set_gapbs[-1].sets[0][k]['l1d_prefetcher']['useful']['dram'] for k in gapbs_keys if k != 'mean'],\n",
    "}\n",
    "\n",
    "df_l1d_pref_useful_gapbs = pandas.DataFrame(\n",
    "    dict_l1d_pref_useful_gapbs, columns=dict_l1d_pref_useful_gapbs.keys(), index=[k for k in gapbs_keys if k != 'mean'])\n",
    "\n",
    "display(np.mean(df_l1d_pref_useful_gapbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l1d_pref_useful = pandas.concat(\n",
    "    [df_l1d_pref_useful_spec, df_l1d_pref_useful_gapbs])\n",
    "\n",
    "df_l1d_pref_useful_mean = pandas.DataFrame({\n",
    "    'l2c': [np.mean(df_l1d_pref_useful['l2c'])],\n",
    "    'llc': [np.mean(df_l1d_pref_useful['llc'])],\n",
    "    'dram': [np.mean(df_l1d_pref_useful['dram'])],\n",
    "}, index=['AVG'])\n",
    "\n",
    "# df_l1d_pref_useful = pandas.concat([df_l1d_pref_useful, df_l1d_pref_useful_mean])\n",
    "\n",
    "display(df_l1d_pref_useful)\n",
    "display(df_l1d_pref_useful_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', 's', 'o', 'x', '>', '<', 'v', '^', 'h', 'D']\n",
    "\n",
    "# Here is the actual plotting material.\n",
    "fig_hit_miss_l1d = plt.figure(\n",
    "    constrained_layout=True, figsize=set_size(fig_width), dpi=500)\n",
    "fig_hit_miss_l1d.tight_layout(pad=0)\n",
    "gs = GridSpec(nrows=1, ncols=5, figure=fig_hit_miss_l1d)\n",
    "\n",
    "ax_l1d_useful_loc, ax_l1d_useful_loc_mean = fig_hit_miss_l1d.add_subplot(\n",
    "    gs[0, :4]), fig_hit_miss_l1d.add_subplot(gs[0, 4:])\n",
    "ax_l1d_useful_loc.margins(x=0, tight=True)\n",
    "\n",
    "xticklabels = df_l1d_pref_useful.index.tolist()\n",
    "xticklabels = [sub_re_trailing_sdc.sub(repl='', string=e) for e in xticklabels]\n",
    "xticklabels = [sub_re_trailing_und.sub(\n",
    "    repl=r'\\_', string=e) for e in xticklabels]\n",
    "\n",
    "key_list = df_l1d_pref_useful.columns.to_list()\n",
    "# key_list = ['hermes_o_pc_based', 'popet_o', 'hermes_o_perceptron_pc_pfn']\n",
    "\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useful))])\n",
    "bars = None\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useful_loc.bar(index + (cat_spacing / 2),\n",
    "                                  df_l1d_pref_useful[e],\n",
    "                                  bottom=prev,\n",
    "                                  edgecolor='black',\n",
    "                                  linewidth=0.2,\n",
    "                                  align='edge',\n",
    "                                  label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += np.array(df_l1d_pref_useful[e].to_list())\n",
    "\n",
    "ax_l1d_useful_loc.axvspan(xmin=0, xmax=len(\n",
    "    df_l1d_pref_useful_spec) + 1, facecolor='grey', alpha=0.25, zorder=-1)\n",
    "# ax_l1d_useful_loc.axvline(x=len(df_l1d_pref_useful_spec) + len(df_l1d_pref_useful_gapbs) + 1, color='red', linestyle='--', linewidth=0.35)\n",
    "\n",
    "# Annotating the 5th to last bar of the plot.\n",
    "ax_l1d_useful_loc.annotate(f'{prev[-4]:.2f}', (bars.patches[-4].get_x() + bars.patches[-4].get_width() / 2 - 3.5, 160\n",
    "                                                ), ha='center', va='center', textcoords='offset points', xytext=(0, 9), size=4)\n",
    "\n",
    "ax_l1d_useful_loc.set_xticks(index)\n",
    "# ax_l1d_useful_loc.set_xticklabels(xticklabels, rotation=90, fontsize=5)\n",
    "ax_l1d_useful_loc.set_xticklabels([])\n",
    "ax_l1d_useful_loc.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25, axis='y')\n",
    "ax_l1d_useful_loc.set_axisbelow(True)\n",
    "\n",
    "ax_l1d_useful_loc.set_ylabel(\n",
    "    'Prefetches Per Kilo\\nInstructions (PPKI)', fontsize=8)\n",
    "\n",
    "ax_l1d_useful_loc.tick_params(axis='both')\n",
    "ax_l1d_useful_loc.tick_params(labeltop=False)\n",
    "ax_l1d_useful_loc.tick_params(axis='x',\n",
    "                               which='both',\n",
    "                               bottom=False,\n",
    "                               top=False)\n",
    "\n",
    "# ax_l1d_useful_loc.set_yscale('log')\n",
    "ax_l1d_useful_loc.set_ylim([0.0, 15.0])\n",
    "\n",
    "for tick in ax_l1d_useful_loc.xaxis.get_major_ticks():\n",
    "    tick.label1.set_horizontalalignment('left')\n",
    "\n",
    "ax_l1d_useful_loc.legend(loc='upper center', edgecolor='white', fancybox=False, framealpha=0.0, ncol=3,\n",
    "                          bbox_to_anchor=(0.5, 1.2),\n",
    "                          fontsize=5\n",
    "                          )\n",
    "\n",
    "# Annotating the benchmark suites on the plots.\n",
    "ax_l1d_useful_loc.annotate(\n",
    "    'SPEC', (len(spec_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "ax_l1d_useful_loc.annotate('GAP', (len(\n",
    "    spec_keys) + len(gapbs_keys) / 2, 125), ha='center', va='center', size=7)\n",
    "\n",
    "# Plotting the mean in a seperate subplot.\n",
    "xticklabels = df_l1d_pref_useful_mean.index.to_list()\n",
    "cat_spacing = 0.075\n",
    "bar_width, index = (1 - cat_spacing) / \\\n",
    "    len(key_list), np.arange(1, len(xticklabels) + 1)\n",
    "\n",
    "colors = cm.get_cmap(plot_cmp)(np.linspace(\n",
    "    0.0, 1.0, len(key_list) + 1, endpoint=True))[1:][::-1]\n",
    "prev = np.array([0.0 for _ in range(len(df_l1d_pref_useful_mean))])\n",
    "\n",
    "for i, (e, c, m) in enumerate(zip(key_list, colors, markers)):\n",
    "    bars = ax_l1d_useful_loc_mean.bar(index + (cat_spacing / 2),\n",
    "                                       df_l1d_pref_useful_mean[e],\n",
    "                                       bottom=prev,\n",
    "                                       edgecolor='black',\n",
    "                                       linewidth=0.2,\n",
    "                                       align='edge',\n",
    "                                       label=labels_dict[e], color=c)\n",
    "\n",
    "    prev += df_l1d_pref_useful_mean[e]\n",
    "\n",
    "ax_l1d_useful_loc_mean.yaxis.set_major_locator(MultipleLocator(2.5))\n",
    "ax_l1d_useful_loc_mean.yaxis.set_major_formatter('{x:.1f}')\n",
    "# ax_l1d_useful_loc_mean.yaxis.set_minor_locator(MultipleLocator(15))\n",
    "# ax_l1d_useful_loc_mean.yaxis.set_minor_formatter('{x:.1f}')\n",
    "\n",
    "ax_l1d_useful_loc_mean.set_ylim([0.0, 2.5])\n",
    "ax_l1d_useful_loc_mean.set_xticks(index)\n",
    "ax_l1d_useful_loc_mean.set_xticklabels([])\n",
    "ax_l1d_useful_loc_mean.bar_label(ax_l1d_useful_loc_mean.containers[-1], labels=[\n",
    "                                  'AVG'], label_type='edge', rotation=0, fontsize=5, padding=3)\n",
    "ax_l1d_useful_loc_mean.grid(\n",
    "    color='grey', linestyle='-', linewidth=0.25)\n",
    "ax_l1d_useful_loc_mean.grid(True, which='minor', color='grey',\n",
    "                             linestyle='--', linewidth=0.2, axis='y')\n",
    "ax_l1d_useful_loc_mean.set_axisbelow(True)\n",
    "\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_l1d_pref_useful.pdf',\n",
    "            format='pdf', dpi='figure')\n",
    "plt.savefig('12_HPCA30_Paper/plots/evaluation/single_core_berti_l1d_pref_useful.png',\n",
    "            format='png', dpi='figure')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
